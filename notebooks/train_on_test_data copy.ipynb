{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportional_train_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_HC/auc.npy'\n",
    "proportional_test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_test/auc.npy'\n",
    "\n",
    "reduced_train_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/auc_raw_HC.npy'\n",
    "reduced_test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/auc_test.npy'\n",
    "\n",
    "ranks_train_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_HC/auc.npy'\n",
    "ranks_test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_test/auc.npy'\n",
    "\n",
    "\n",
    "train_matrix = proportional_train_matrix\n",
    "test_matrix = proportional_test_matrix \n",
    "\n",
    "# train_matrix = ranks_train_matrix\n",
    "# test_matrix = ranks_test_matrix\n",
    "\n",
    "# train_matrix = reduced_train_matrix\n",
    "# test_matrix = reduced_test_matrix\n",
    "\n",
    "train_matrix, test_matrix = test_matrix, train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_matrix  = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/HC/max.npy'\n",
    "# test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/test/max.npy'\n",
    "\n",
    "# train_matrix, test_matrix = test_matrix, train_matrix\n",
    "def draw_all_subjects(matrix):\n",
    "    N = matrix.shape[0]  # Длина массива\n",
    "    sub_num = N // 5\n",
    "\n",
    "    subjects = np.array_split(matrix, sub_num)\n",
    "    for idx, sub in enumerate(subjects):\n",
    "        print(f'sub-{idx:02d}')\n",
    "        draw_heat_map(subjects[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def z_score_matrix(matrix):\n",
    "    shape = matrix.shape\n",
    "\n",
    "    # 1. Разбиваем матрицу на группы по 5 элементов\n",
    "    flattened = matrix.flatten()  # Преобразуем в 1D-массив\n",
    "    num_groups = len(flattened) // 5\n",
    "    groups = flattened[:num_groups * 5].reshape(-1, 5)  # Группы по 5 элементов\n",
    "\n",
    "    # 2. Вычисляем z-показатели для каждой группы\n",
    "    z_scores = np.zeros_like(groups)\n",
    "    for i in range(groups.shape[0]):\n",
    "        group = groups[i]\n",
    "        mean = np.mean(group)\n",
    "        std = np.std(group)\n",
    "        if std != 0:\n",
    "            z_scores[i] = (group - mean) / std\n",
    "        else:\n",
    "            z_scores[i] = 0  # Если все элементы одинаковые\n",
    "\n",
    "    # 3. Собираем обратно в матрицу\n",
    "    flattened_z = z_scores.flatten()\n",
    "    # Если исходная длина не делилась на 5, добавляем оставшиеся элементы без изменений\n",
    "    if len(flattened) % 5 != 0:\n",
    "        remaining = flattened[num_groups * 5:]\n",
    "        flattened_z = np.concatenate([flattened_z, remaining])\n",
    "\n",
    "    # Преобразуем обратно в исходную размерность\n",
    "    result_matrix = flattened_z.reshape(shape)\n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def prepare_data(train_matrix):\n",
    "    matrix = np.load(train_matrix)\n",
    "    N = matrix.shape[0]  # Длина массива\n",
    "    sub_num = N // 5    # Количество испытуемых\n",
    "\n",
    "    labels = np.zeros(N, dtype=int)  # Создаем массив из нулей\n",
    "    labels[3::5] = 1  # Каждый 4-й элемен\n",
    "    print(matrix.shape)\n",
    "\n",
    "    X = matrix\n",
    "    y = labels\n",
    "\n",
    "\n",
    "    # Группы для разделения\n",
    "    groups = np.repeat(np.arange(sub_num), 5)  # [0,0,0,0,0, 1,1,1,1,1,...]\n",
    "\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=30)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups))\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, classification_report\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "from fmri_processing.utils import draw_heat_map\n",
    "\n",
    "def train_best_model_by_recall(X, y, groups, target_class=1, test_size=0.3, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Обучает модели и возвращает лучшую по recall для указанного класса\n",
    "    \n",
    "    Параметры:\n",
    "    X - признаки\n",
    "    y - целевая переменная\n",
    "    groups - группы для кросс-валидации\n",
    "    target_class - класс, для которого оптимизируем recall (по умолчанию 1)\n",
    "    test_size - доля тестовой выборки\n",
    "    random_state - для воспроизводимости\n",
    "    verbose - вывод информации о процессе обучения\n",
    "    \"\"\"\n",
    "    # 1. Разделение на train/test с сохранением групп\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups))\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    groups_train = groups[train_idx]\n",
    "    \n",
    "    # 2. Инициализация моделей\n",
    "    models = {\n",
    "        \"Logistic Regression\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LogisticRegression(class_weight='balanced', \n",
    "                                       max_iter=1000, \n",
    "                                       random_state=random_state))\n",
    "        ]),\n",
    "        \"Random Forest\": RandomForestClassifier(class_weight='balanced_subsample', \n",
    "                                              random_state=random_state),\n",
    "        \"SVM\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', SVC(kernel='rbf', \n",
    "                         class_weight='balanced', \n",
    "                         probability=True, \n",
    "                         random_state=random_state))\n",
    "        ]),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            scale_pos_weight=4,  # Автоматический расчет\n",
    "            random_state=random_state\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # 3. Кросс-валидация по группам\n",
    "    gss = GroupShuffleSplit(n_splits=5, test_size=0.2, random_state=random_state)\n",
    "    model_recalls = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        recall_scores = []\n",
    "        \n",
    "        for fold, (train_idx_fold, val_idx_fold) in enumerate(gss.split(X_train, y_train, groups_train)):\n",
    "            model.fit(X_train[train_idx_fold], y_train[train_idx_fold])\n",
    "            y_pred = model.predict(X_train[val_idx_fold])\n",
    "            recall = recall_score(y_train[val_idx_fold], y_pred, pos_label=target_class)\n",
    "            recall_scores.append(recall)\n",
    "        \n",
    "        print(recall_scores)\n",
    "        mean_recall = np.mean(recall_scores)\n",
    "        std_recall = np.std(recall_scores)\n",
    "        model_recalls.append((name, mean_recall, std_recall, model))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{name:<20} | Recall (class {target_class}): {mean_recall:.3f} ± {std_recall:.3f}\")\n",
    "\n",
    "    # 4. Выбор лучшей модели\n",
    "    best_name, best_recall, best_std, best_model = max(model_recalls, key=lambda x: x[1])\n",
    "    \n",
    "    # 5. Финальное обучение на полном train наборе\n",
    "    best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 6. Оценка на тестовом наборе\n",
    "    test_recall = recall_score(y_test, best_model.predict(X_test), pos_label=target_class)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"BEST MODEL: {best_name}\")\n",
    "        print(f\"CV Recall (class {target_class}): {best_recall:.3f} ± {best_std:.3f}\")\n",
    "        print(f\"Test Recall (class {target_class}): {test_recall:.3f}\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 132)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prepare_data(train_matrix)\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m train_best_model_by_recall(\u001b[43mX\u001b[49m, y, groups, \u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "prepare_data(train_matrix)\n",
    "model = train_best_model_by_recall(X, y, groups, 1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88        68\n",
      "           1       0.50      0.47      0.48        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.68      0.68      0.68        85\n",
      "weighted avg       0.80      0.80      0.80        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matrix_test = np.load(test_matrix)\n",
    "matrix_test = z_score_matrix(matrix_test)\n",
    "N_test = matrix_test.shape[0]  # Длина массива\n",
    "sub_num_test = N_test // 5\n",
    "\n",
    "labels_test = np.zeros(N_test, dtype=int)  # Создаем массив из нулей\n",
    "labels_test[3::5] = 1  # Каждый 4-й элемен\n",
    "print(classification_report(labels_test, model.predict(matrix_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
