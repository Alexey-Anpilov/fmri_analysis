{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, classification_report\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from fmri_processing.utils import draw_heat_map\n",
    "from fmri_processing.functions import funcs\n",
    "import os\n",
    "from fmri_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GroupKFold, GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "\n",
    "def train_best_model_by_recall(train_matrix, target_class=1, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Обучает модели с оптимизацией параметров и возвращает ансамбль моделей\n",
    "    \n",
    "    Изменения:\n",
    "    - Добавлена оптимизация гиперпараметров\n",
    "    - Включено ансамблирование\n",
    "    - Добавлена балансировка классов\n",
    "    - Улучшена обработка групп\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Загрузка данных и подготовка\n",
    "    matrix = np.load(train_matrix)\n",
    "    N = matrix.shape[0]\n",
    "    sub_num = N // 5\n",
    "\n",
    "    labels = np.zeros(N, dtype=int)\n",
    "    labels[3::5] = 1\n",
    "    \n",
    "    X = matrix\n",
    "    y = labels\n",
    "    groups = np.repeat(np.arange(sub_num), 5)\n",
    "\n",
    "    # 2. Определение пайплайнов с балансировкой\n",
    "    def create_pipeline(model):\n",
    "        return ImbPipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('smote', SMOTE(random_state=random_state)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "\n",
    "    # 3. Инициализация моделей с параметрами для оптимизации\n",
    "    models = {\n",
    "        \"Logistic Regression\": {\n",
    "            'pipeline': create_pipeline(LogisticRegression(max_iter=1000)),\n",
    "            'params': {\n",
    "                'model__C': [0.1, 1, 10],\n",
    "                'model__class_weight': ['balanced', None],\n",
    "                'model__solver': ['lbfgs', 'saga']\n",
    "            }\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            'pipeline': create_pipeline(RandomForestClassifier()),\n",
    "            'params': {\n",
    "                'model__n_estimators': [100, 200],\n",
    "                'model__max_depth': [None, 10],\n",
    "                'model__class_weight': ['balanced_subsample', None]\n",
    "            }\n",
    "        },\n",
    "        \"SVM\": {\n",
    "            'pipeline': create_pipeline(SVC(probability=True)),\n",
    "            'params': {\n",
    "                'model__C': [0.1, 1, 10],\n",
    "                'model__kernel': ['rbf', 'linear'],\n",
    "                'model__class_weight': ['balanced', None]\n",
    "            }\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            'pipeline': create_pipeline(XGBClassifier(eval_metric='logloss')),\n",
    "            'params': {\n",
    "                'model__scale_pos_weight': [1, (len(y) - sum(y)) / sum(y)],\n",
    "                'model__max_depth': [3, 5],\n",
    "                'model__learning_rate': [0.1, 0.01]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 4. Оптимизация гиперпараметров с групповой валидацией\n",
    "    optimized_models = {}\n",
    "    recall_scorer = make_scorer(recall_score, pos_label=target_class)\n",
    "    \n",
    "    for name, config in models.items():\n",
    "        gs = GridSearchCV(\n",
    "            estimator=config['pipeline'],\n",
    "            param_grid=config['params'],\n",
    "            cv=GroupKFold(n_splits=5),\n",
    "            scoring=recall_scorer,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        gs.fit(X, y, groups=groups)\n",
    "        optimized_models[name] = gs.best_estimator_\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{name} - лучшие параметры: {gs.best_params_}\")\n",
    "            print(f\"Recall (CV): {gs.best_score_:.3f}\\n\")\n",
    "\n",
    "    # 5. Создание ансамбля\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[(name, model) for name, model in optimized_models.items()],\n",
    "        voting='soft',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # 6. Обучение ансамбля с групповой валидацией\n",
    "    logo = LeaveOneGroupOut()\n",
    "    recall_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in logo.split(X, y, groups=groups):\n",
    "        ensemble.fit(X[train_idx], y[train_idx])\n",
    "        y_pred = ensemble.predict(X[val_idx])\n",
    "        recall = recall_score(y[val_idx], y_pred, pos_label=target_class)\n",
    "        recall_scores.append(recall)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Ансамбль - Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "    \n",
    "    # 7. Финальное обучение на всех данных\n",
    "    final_models = {**optimized_models, 'Ensemble': ensemble.fit(X, y)}\n",
    "    \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_on_test(train_matrix, test_matrix):\n",
    "    models = train_best_model_by_recall(train_matrix)\n",
    "    for name, model in models.items():\n",
    "        print(f'Model: {name}')\n",
    "        matrix_test = np.load(test_matrix)\n",
    "        N_test = matrix_test.shape[0]  # Длина массива\n",
    "        sub_num_test = N_test // 5\n",
    "\n",
    "        labels_test = np.zeros(N_test, dtype=int)  # Создаем массив из нулей\n",
    "        labels_test[3::5] = 1  # Каждый 4-й элемен\n",
    "        print(model.predict(matrix_test))\n",
    "        print(classification_report(labels_test, model.predict(matrix_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_different_params(train_matrix_base, test_matrix_base):\n",
    "    for func_name in funcs.keys():\n",
    "        if func_name in ('max_min', 'min'):\n",
    "            continue\n",
    "        train_matrix = os.path.join(train_matrix_base, func_name + '.npy')\n",
    "        test_matrix = os.path.join(test_matrix_base, func_name + '.npy')\n",
    "        print('-'*10 + func_name + '-'*10)\n",
    "        train_and_predict_on_test(train_matrix, test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/home/aaanpilov/diploma/project'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = np.load(os.path.join(base_dir, 'numpy_data/card_hc_data/1136_DOROSHENKO_N_I__1136.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-15 22:41:42,147][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1136_DOROSHENKO_N_I__1136.npy\n",
      "[2025-05-15 22:41:42,149][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1136_DOROSHENKO_N_I__1136/Дороенко карта.txt\n",
      "[2025-05-15 22:41:42,152][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1146_KRYLOV_V_O__1146.npy\n",
      "[2025-05-15 22:41:42,155][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1146_KRYLOV_V_O__1146/Крылов карта.txt\n",
      "[2025-05-15 22:41:42,158][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1152_BAKAEV_A_T__1152.npy\n",
      "[2025-05-15 22:41:42,162][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1152_BAKAEV_A_T__1152/Бакаев карта.txt\n",
      "[2025-05-15 22:41:42,167][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1153_ZYZYKIN_A_P__1153.npy\n",
      "[2025-05-15 22:41:42,169][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1153_ZYZYKIN_A_P__1153/ЗызыкинА карта.txt\n",
      "[2025-05-15 22:41:42,172][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1168_NESTER_A_O__1168.npy\n",
      "[2025-05-15 22:41:42,174][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1168_NESTER_A_O__1168/Нестер карта.txt\n",
      "[2025-05-15 22:41:42,176][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1224_BALAKIN_K_A__1224.npy\n",
      "[2025-05-15 22:41:42,179][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1224_BALAKIN_K_A__1224/Балакин карта нет.txt\n",
      "[2025-05-15 22:41:42,184][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1329_Lisitsin_I_S.npy\n",
      "[2025-05-15 22:41:42,187][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1329_Lisitsin_I_S/1329 Лисицин карта нет + счёт.txt\n",
      "[2025-05-15 22:41:42,190][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1339_Berdikov_P_G.npy\n",
      "[2025-05-15 22:41:42,192][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1339_Berdikov_P_G/1339 Бердиков карта + счёт.txt\n",
      "[2025-05-15 22:41:42,196][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1342_Mozgovoi_V_V.npy\n",
      "[2025-05-15 22:41:42,198][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1342_Mozgovoi_V_V/1342 Мозговой карта нет + счёт.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-05-15 22:41:42,202][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1350_Matveev_M_I.npy\n",
      "[2025-05-15 22:41:42,205][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1350_Matveev_M_I/1350 Матвеев карта нет + счёт.txt\n",
      "[2025-05-15 22:41:42,209][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1351_Kruglov_V_A.npy\n",
      "[2025-05-15 22:41:42,212][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1351_Kruglov_V_A/1351 Круглов карта нет + счёт.txt\n",
      "[2025-05-15 22:41:42,215][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1352_Zemkin_V_A.npy\n",
      "[2025-05-15 22:41:42,217][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1352_Zemkin_V_A/1352 Земкин карта нет + счёт.txt\n",
      "[2025-05-15 22:41:42,222][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1357_Kozhanov_K_D.npy\n",
      "[2025-05-15 22:41:42,224][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1357_Kozhanov_K_D/1357 Кожанов карта + счёт.txt\n",
      "[2025-05-15 22:41:42,228][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1364_Nabiev_T_R.npy\n",
      "[2025-05-15 22:41:42,230][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1364_Nabiev_T_R/1364 Набиев карта + счёт.txt\n",
      "[2025-05-15 22:41:42,233][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1365_Dolgikh_S_V.npy\n",
      "[2025-05-15 22:41:42,235][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1365_Dolgikh_S_V/1365 Долгих карта.txt\n",
      "[2025-05-15 22:41:42,240][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1366_Dyatlov_G_I.npy\n",
      "[2025-05-15 22:41:42,242][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1366_Dyatlov_G_I/1366 Дятлов карта нет + счёт.txt\n",
      "[2025-05-15 22:41:42,246][INFO][DataLoader] Loading preprocessed data from: /home/aaanpilov/diploma/project/numpy_data/card_hc_data/1373_Russak_D_A.npy\n",
      "[2025-05-15 22:41:42,249][INFO][DataLoader] Parsing time-file: /home/aaanpilov/diploma/project/data/card_hc_data/1373_Russak_D_A/1373 Руссак карта нет + счёт.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622.0\n",
      "(653, 132)\n",
      "634.28\n",
      "(689, 132)\n",
      "611.2\n",
      "(630, 132)\n",
      "653.28\n",
      "(673, 132)\n",
      "609.96\n",
      "(634, 132)\n",
      "693.38\n",
      "(710, 132)\n",
      "566.62\n",
      "(523, 132)\n",
      "591.8\n",
      "(546, 132)\n",
      "559.9\n",
      "(517, 132)\n",
      "549.06\n",
      "(506, 132)\n",
      "574.58\n",
      "(530, 132)\n",
      "571.96\n",
      "(528, 132)\n",
      "560.4\n",
      "(517, 132)\n",
      "549.9\n",
      "(506, 132)\n",
      "572.74\n",
      "(526, 132)\n",
      "590.1\n",
      "(542, 132)\n",
      "637.56\n",
      "(589, 132)\n"
     ]
    }
   ],
   "source": [
    "config_path = os.path.join(base_dir, 'configs/card_hc_data.yaml')\n",
    "\n",
    "subjects = process_config(config_path)\n",
    "data_loader = DataLoader()\n",
    "\n",
    "for subject in subjects:\n",
    "    data = data_loader.load_from_npy(subject['numpy_path'])\n",
    "    # Получаем и обрабатываем данные\n",
    "    events = data_loader.load_events(subject['events_path'])\n",
    "    print(events['onset'].iloc[-1])\n",
    "\n",
    "    print(np.load(subject['numpy_path']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_all_subjects(matrix):\n",
    "    N = matrix.shape[0]  # Длина массива\n",
    "    sub_num = N // 5\n",
    "\n",
    "    subjects = np.array_split(matrix, sub_num)\n",
    "    for idx, sub in enumerate(subjects):\n",
    "        print(f'sub-{idx:02d}')\n",
    "        draw_heat_map(subjects[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_average_stimulus = os.path.join(base_dir, 'numpy_matrixes/average_stimulus/card_hc_data/max.npy')\n",
    "card_ranks = os.path.join(base_dir, 'numpy_matrixes/ranks_matrix/raw_card_hc_data/max.npy')\n",
    "\n",
    "train_average_stimulus = os.path.join(base_dir, 'numpy_matrixes/average_stimulus/hc_data/max.npy')\n",
    "train_ranks = os.path.join(base_dir, 'numpy_matrixes/ranks_matrix/hc_data/auc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - лучшие параметры: {'model__C': 10, 'model__class_weight': 'balanced', 'model__solver': 'saga'}\n",
      "Recall (CV): 0.667\n",
      "\n",
      "Random Forest - лучшие параметры: {'model__class_weight': None, 'model__max_depth': None, 'model__n_estimators': 100}\n",
      "Recall (CV): 0.633\n",
      "\n",
      "SVM - лучшие параметры: {'model__C': 0.1, 'model__class_weight': 'balanced', 'model__kernel': 'rbf'}\n",
      "Recall (CV): 0.617\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - лучшие параметры: {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__scale_pos_weight': 4.0}\n",
      "Recall (CV): 0.733\n",
      "\n",
      "Ансамбль - Recall: 0.588 ± 0.492\n",
      "Model: Logistic Regression\n",
      "[0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1\n",
      " 0 0 1 0 0 0 0 1 0 0 1 1 0 1 0 1 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0\n",
      " 0 0 0 1 0 0 1 1 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.63      0.72        68\n",
      "           1       0.26      0.53      0.35        17\n",
      "\n",
      "    accuracy                           0.61        85\n",
      "   macro avg       0.55      0.58      0.54        85\n",
      "weighted avg       0.73      0.61      0.65        85\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 1 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.59      0.68        68\n",
      "           1       0.20      0.41      0.27        17\n",
      "\n",
      "    accuracy                           0.55        85\n",
      "   macro avg       0.50      0.50      0.47        85\n",
      "weighted avg       0.68      0.55      0.60        85\n",
      "\n",
      "Model: SVM\n",
      "[0 0 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.79      0.82        68\n",
      "           1       0.33      0.41      0.37        17\n",
      "\n",
      "    accuracy                           0.72        85\n",
      "   macro avg       0.59      0.60      0.59        85\n",
      "weighted avg       0.74      0.72      0.73        85\n",
      "\n",
      "Model: XGBoost\n",
      "[0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 0 1 1 0 1 1 1\n",
      " 1 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 0 1 0 1 1 1 0 1\n",
      " 0 0 1 1 0 1 1 1 0 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.34      0.48        68\n",
      "           1       0.21      0.71      0.32        17\n",
      "\n",
      "    accuracy                           0.41        85\n",
      "   macro avg       0.52      0.52      0.40        85\n",
      "weighted avg       0.70      0.41      0.45        85\n",
      "\n",
      "Model: Ensemble\n",
      "[0 1 0 1 0 1 0 1 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1\n",
      " 0 1 1 0 1 0 0 1 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1 1 1 0 1 0 1 0 1 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 1 1 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.54      0.65        68\n",
      "           1       0.23      0.53      0.32        17\n",
      "\n",
      "    accuracy                           0.54        85\n",
      "   macro avg       0.52      0.54      0.49        85\n",
      "weighted avg       0.70      0.54      0.59        85\n",
      "\n",
      "----------max----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - лучшие параметры: {'model__C': 0.1, 'model__class_weight': 'balanced', 'model__solver': 'lbfgs'}\n",
      "Recall (CV): 0.683\n",
      "\n",
      "Random Forest - лучшие параметры: {'model__class_weight': 'balanced_subsample', 'model__max_depth': 10, 'model__n_estimators': 200}\n",
      "Recall (CV): 0.700\n",
      "\n",
      "SVM - лучшие параметры: {'model__C': 10, 'model__class_weight': 'balanced', 'model__kernel': 'rbf'}\n",
      "Recall (CV): 0.633\n",
      "\n",
      "XGBoost - лучшие параметры: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__scale_pos_weight': 4.0}\n",
      "Recall (CV): 0.800\n",
      "\n",
      "Ансамбль - Recall: 0.647 ± 0.478\n",
      "Model: Logistic Regression\n",
      "[0 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0 0 1 1 0\n",
      " 0 1 1 0 1 0 1 1 1 0 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 0\n",
      " 0 0 0 1 0 0 1 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.59      0.69        68\n",
      "           1       0.24      0.53      0.33        17\n",
      "\n",
      "    accuracy                           0.58        85\n",
      "   macro avg       0.54      0.56      0.51        85\n",
      "weighted avg       0.72      0.58      0.62        85\n",
      "\n",
      "Model: Random Forest\n",
      "[0 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 1 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 0 1 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1\n",
      " 0 0 1 1 0 1 1 1 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.46      0.58        68\n",
      "           1       0.21      0.59      0.31        17\n",
      "\n",
      "    accuracy                           0.48        85\n",
      "   macro avg       0.51      0.52      0.45        85\n",
      "weighted avg       0.70      0.48      0.53        85\n",
      "\n",
      "Model: SVM\n",
      "[0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 1 0 1 0 1 0 0 1 1 0 0 1 1 0 1 0 0 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76        68\n",
      "           1       0.23      0.35      0.28        17\n",
      "\n",
      "    accuracy                           0.64        85\n",
      "   macro avg       0.52      0.53      0.52        85\n",
      "weighted avg       0.70      0.64      0.66        85\n",
      "\n",
      "Model: XGBoost\n",
      "[0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0\n",
      " 0 1 1 0 1 0 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 1\n",
      " 0 0 1 1 1 0 1 0 0 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.43      0.56        68\n",
      "           1       0.20      0.59      0.30        17\n",
      "\n",
      "    accuracy                           0.46        85\n",
      "   macro avg       0.50      0.51      0.43        85\n",
      "weighted avg       0.69      0.46      0.51        85\n",
      "\n",
      "Model: Ensemble\n",
      "[0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 0 1 1 0 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 0 1 0 1 1 1 0 0\n",
      " 0 0 1 1 0 0 1 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.57      0.67        68\n",
      "           1       0.22      0.47      0.30        17\n",
      "\n",
      "    accuracy                           0.55        85\n",
      "   macro avg       0.51      0.52      0.48        85\n",
      "weighted avg       0.69      0.55      0.60        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_different_params(os.path.join(base_dir, 'numpy_matrixes/ranks_matrix/raw_hc_data'), os.path.join(base_dir, 'numpy_matrixes/ranks_matrix/raw_card_hc_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'draw_all_subjects' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdraw_all_subjects\u001b[49m(np\u001b[38;5;241m.\u001b[39mload(test_ranks))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'draw_all_subjects' is not defined"
     ]
    }
   ],
   "source": [
    "draw_all_subjects(np.load(test_ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
