{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, classification_report\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from fmri_processing.utils import draw_heat_map\n",
    "from fmri_processing.functions import funcs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_matrix  = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/HC/max.npy'\n",
    "# test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/test/max.npy'\n",
    "\n",
    "# train_matrix, test_matrix = test_matrix, train_matrix\n",
    "def draw_all_subjects(matrix):\n",
    "    N = matrix.shape[0]  # Длина массива\n",
    "    sub_num = N // 5\n",
    "\n",
    "    subjects = np.array_split(matrix, sub_num)\n",
    "    for idx, sub in enumerate(subjects):\n",
    "        print(f'sub-{idx:02d}')\n",
    "        draw_heat_map(subjects[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def z_score_matrix(matrix):\n",
    "    shape = matrix.shape\n",
    "\n",
    "    # 1. Разбиваем матрицу на группы по 5 элементов\n",
    "    flattened = matrix.flatten()  # Преобразуем в 1D-массив\n",
    "    num_groups = len(flattened) // 5\n",
    "    groups = flattened[:num_groups * 5].reshape(-1, 5)  # Группы по 5 элементов\n",
    "\n",
    "    # 2. Вычисляем z-показатели для каждой группы\n",
    "    z_scores = np.zeros_like(groups)\n",
    "    for i in range(groups.shape[0]):\n",
    "        group = groups[i]\n",
    "        mean = np.mean(group)\n",
    "        std = np.std(group)\n",
    "        if std != 0:\n",
    "            z_scores[i] = (group - mean) / std\n",
    "        else:\n",
    "            z_scores[i] = 0  # Если все элементы одинаковые\n",
    "\n",
    "    # 3. Собираем обратно в матрицу\n",
    "    flattened_z = z_scores.flatten()\n",
    "    # Если исходная длина не делилась на 5, добавляем оставшиеся элементы без изменений\n",
    "    if len(flattened) % 5 != 0:\n",
    "        remaining = flattened[num_groups * 5:]\n",
    "        flattened_z = np.concatenate([flattened_z, remaining])\n",
    "\n",
    "    # Преобразуем обратно в исходную размерность\n",
    "    result_matrix = flattened_z.reshape(shape)\n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_matrix):\n",
    "    matrix = np.load(train_matrix)\n",
    "    N = matrix.shape[0]  # Длина массива\n",
    "    sub_num = N // 5    # Количество испытуемых\n",
    "\n",
    "    labels = np.zeros(N, dtype=int)  # Создаем массив из нулей\n",
    "    labels[3::5] = 1  # Каждый 4-й элемен\n",
    "    print(matrix.shape)\n",
    "\n",
    "    X = matrix\n",
    "    y = labels\n",
    "\n",
    "\n",
    "    # Группы для разделения\n",
    "    groups = np.repeat(np.arange(sub_num), 5)  # [0,0,0,0,0, 1,1,1,1,1,...]\n",
    "\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=30)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups))\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model_by_recall_(train_matrix, target_class=1, test_size=0.3, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Обучает модели и возвращает лучшую по recall для указанного класса\n",
    "    \n",
    "    Параметры:\n",
    "    X - признаки\n",
    "    y - целевая переменная\n",
    "    groups - группы для кросс-валидации\n",
    "    target_class - класс, для которого оптимизируем recall (по умолчанию 1)\n",
    "    test_size - доля тестовой выборки\n",
    "    random_state - для воспроизводимости\n",
    "    verbose - вывод информации о процессе обучения\n",
    "    \"\"\"\n",
    "    \n",
    "    matrix = np.load(train_matrix)\n",
    "    N = matrix.shape[0]  # Длина массива\n",
    "    sub_num = N // 5    # Количество испытуемых\n",
    "\n",
    "    labels = np.zeros(N, dtype=int)  # Создаем массив из нулей\n",
    "    labels[3::5] = 1  # Каждый 4-й элемен\n",
    "    print(matrix.shape)\n",
    "\n",
    "    X = matrix\n",
    "    y = labels\n",
    "\n",
    "\n",
    "    # Группы для разделения\n",
    "    groups = np.repeat(np.arange(sub_num), 5)  # [0,0,0,0,0, 1,1,1,1,1,...]\n",
    "\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=30)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups))\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    \n",
    "    # 1. Разделение на train/test с сохранением групп\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups))\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    groups_train = groups[train_idx]\n",
    "    \n",
    "    # 2. Инициализация моделей\n",
    "    models = {\n",
    "        \"Logistic Regression\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LogisticRegression(class_weight='balanced', \n",
    "                                       max_iter=1000, \n",
    "                                       random_state=random_state))\n",
    "        ]),\n",
    "        \"Random Forest\": RandomForestClassifier(class_weight='balanced_subsample', \n",
    "                                              random_state=random_state),\n",
    "        \"SVM\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', SVC(kernel='rbf', \n",
    "                         class_weight='balanced', \n",
    "                         probability=True, \n",
    "                         random_state=random_state))\n",
    "        ]),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            scale_pos_weight=4,  # Автоматический расчет\n",
    "            random_state=random_state\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # 3. Кросс-валидация по группам\n",
    "    gss = GroupShuffleSplit(n_splits=5, test_size=0.3, random_state=random_state)\n",
    "    model_recalls = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        recall_scores = []\n",
    "        \n",
    "        for fold, (train_idx_fold, val_idx_fold) in enumerate(gss.split(X_train, y_train, groups_train)):\n",
    "            model.fit(X_train[train_idx_fold], y_train[train_idx_fold])\n",
    "            y_pred = model.predict(X_train[val_idx_fold])\n",
    "            recall = recall_score(y_train[val_idx_fold], y_pred, pos_label=target_class)\n",
    "            recall_scores.append(recall)\n",
    "        \n",
    "        print(recall_scores)\n",
    "        mean_recall = np.mean(recall_scores)\n",
    "        std_recall = np.std(recall_scores)\n",
    "        model_recalls.append((name, mean_recall, std_recall, model))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{name:<20} | Recall (class {target_class}): {mean_recall:.3f} ± {std_recall:.3f}\")\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "    # # 4. Выбор лучшей модели\n",
    "    # best_name, best_recall, best_std, best_model = max(model_recalls, key=lambda x: x[1])\n",
    "    \n",
    "    # # 5. Финальное обучение на полном train наборе\n",
    "    # best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # # 6. Оценка на тестовом наборе\n",
    "    # test_recall = recall_score(y_test, best_model.predict(X_test), pos_label=target_class)\n",
    "    \n",
    "    # if verbose:\n",
    "    #     print(f\"\\n{'='*50}\")\n",
    "    #     print(f\"BEST MODEL: {best_name}\")\n",
    "    #     print(f\"CV Recall (class {target_class}): {best_recall:.3f} ± {best_std:.3f}\")\n",
    "    #     print(f\"Test Recall (class {target_class}): {test_recall:.3f}\")\n",
    "    #     print(\"=\"*50)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model_by_recall(train_matrix, target_class=1, test_size=0.3, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Обучает модели и возвращает лучшую по recall для указанного класса\n",
    "    \n",
    "    Параметры:\n",
    "    train_matrix - путь к файлу с матрицей признаков\n",
    "    target_class - класс, для которого оптимизируем recall\n",
    "    test_size - доля валидационной выборки в кросс-валидации\n",
    "    random_state - для воспроизводимости\n",
    "    verbose - вывод информации о процессе обучения\n",
    "    \n",
    "    Возвращает:\n",
    "    Лучшую модель (по recall на валидации), метрики моделей\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Загрузка данных и подготовка\n",
    "    matrix = np.load(train_matrix)\n",
    "    N = matrix.shape[0]\n",
    "    sub_num = N // 5\n",
    "\n",
    "    labels = np.zeros(N, dtype=int)\n",
    "    labels[3::5] = 1\n",
    "    \n",
    "    X = matrix\n",
    "    y = labels\n",
    "    groups = np.repeat(np.arange(sub_num), 5)\n",
    "\n",
    "    # 2. Инициализация моделей\n",
    "    models = {\n",
    "        \"Logistic Regression\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LogisticRegression(class_weight='balanced', \n",
    "                                       max_iter=1000, \n",
    "                                       random_state=random_state))\n",
    "        ]),\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "    # from sklearn.model_selection import RandomizedSearchCV\n",
    "    # from scipy.stats import loguniform  # для логарифмического распределения C\n",
    "\n",
    "    # param_dist = {\n",
    "    #     'model__C': loguniform(1e-4, 100),  # C в диапазоне [0.0001, 100]\n",
    "    #     'model__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    #     'model__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    #     'model__l1_ratio': [0, 0.25, 0.5, 0.75, 1]  # для elasticnet\n",
    "    # }\n",
    "\n",
    "    # random_search = RandomizedSearchCV(\n",
    "    #     estimator=models['Logistic Regression'],\n",
    "    #     param_distributions=param_dist,\n",
    "    #     n_iter=50,  # количество случайных комбинаций\n",
    "    #     scoring='accuracy',\n",
    "    #     cv=5,\n",
    "    #     n_jobs=-1,\n",
    "    #     verbose=1,\n",
    "    #     random_state=random_state\n",
    "    # )\n",
    "\n",
    "    # models['Logistic Regression'] = random_search\n",
    "\n",
    "    # 3. Кросс-валидация по группам\n",
    "    gss = GroupShuffleSplit(n_splits=5, test_size=test_size, random_state=random_state)\n",
    "    model_recalls = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        recall_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in gss.split(X, y, groups):\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    "            y_pred = model.predict(X[val_idx])\n",
    "            recall = recall_score(y[val_idx], y_pred, pos_label=target_class)\n",
    "            recall_scores.append(recall)\n",
    "        \n",
    "        mean_recall = np.mean(recall_scores)\n",
    "        std_recall = np.std(recall_scores)\n",
    "        model_recalls.append((name, mean_recall, std_recall, model))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{name:<20} | Recall (class {target_class}): {mean_recall:.3f} ± {std_recall:.3f}\")\n",
    "        model.fit(X, y)\n",
    "    # # 4. Выбор лучшей модели\n",
    "    # best_model_info = max(model_recalls, key=lambda x: x[1])\n",
    "    # best_model = best_model_info[3]\n",
    "    \n",
    "    # # 5. Финальное обучение на всех данных\n",
    "    # best_model.fit(X, y)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def train_best_model_by_recall(train_matrix, target_class=1, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Обучает модели и возвращает лучшую по recall для указанного класса\n",
    "    \n",
    "    Параметры:\n",
    "    train_matrix - путь к файлу с матрицей признаков\n",
    "    target_class - класс, для которого оптимизируем recall\n",
    "    random_state - для воспроизводимости\n",
    "    verbose - вывод информации о процессе обучения\n",
    "    \n",
    "    Возвращает:\n",
    "    Лучшую модель (по recall на валидации), метрики моделей\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Загрузка данных и подготовка\n",
    "    matrix = np.load(train_matrix)\n",
    "    N = matrix.shape[0]\n",
    "    sub_num = N // 5\n",
    "\n",
    "    labels = np.zeros(N, dtype=int)\n",
    "    labels[3::5] = 1\n",
    "    \n",
    "    X = matrix\n",
    "    y = labels\n",
    "    groups = np.repeat(np.arange(sub_num), 5)\n",
    "\n",
    "    # 2. Инициализация моделей\n",
    "    models = {\n",
    "        \"Logistic Regression\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LogisticRegression(class_weight='balanced', \n",
    "                                       max_iter=1000, \n",
    "                                       random_state=random_state))\n",
    "        ]),\n",
    "        \"Random Forest\": RandomForestClassifier(\n",
    "            class_weight='balanced_subsample', \n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"SVM\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', SVC(kernel='rbf', \n",
    "                         class_weight='balanced', \n",
    "                         probability=True, \n",
    "                         random_state=random_state))\n",
    "        ]),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            scale_pos_weight=(len(y) - sum(y)) / sum(y),\n",
    "            random_state=random_state,\n",
    "            eval_metric='logloss'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # 3. Кросс-валидация с LeaveOneGroupOut\n",
    "    logo = LeaveOneGroupOut()\n",
    "    model_recalls = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        recall_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in logo.split(X, y, groups=groups):\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    "            y_pred = model.predict(X[val_idx])\n",
    "            recall = recall_score(y[val_idx], y_pred, pos_label=target_class)\n",
    "            recall_scores.append(recall)\n",
    "        \n",
    "        mean_recall = np.mean(recall_scores)\n",
    "        std_recall = np.std(recall_scores)\n",
    "        model_recalls.append((name, mean_recall, std_recall, model))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{name:<20} | Recall (class {target_class}): {mean_recall:.3f} ± {std_recall:.3f}\")\n",
    "\n",
    "        model.fit(X,y)\n",
    "    # # 4. Выбор и финальное обучение лучшей модели\n",
    "    # best_model_info = max(model_recalls, key=lambda x: x[1])\n",
    "    # best_model = best_model_info[3].fit(X, y)  # Обучаем на всех данных\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_on_test(train_matrix, test_matrix):\n",
    "    models = train_best_model_by_recall(train_matrix)\n",
    "    for name, model in models.items():\n",
    "        print(f'Model: {name}')\n",
    "        matrix_test = np.load(test_matrix)\n",
    "        N_test = matrix_test.shape[0]  # Длина массива\n",
    "        sub_num_test = N_test // 5\n",
    "\n",
    "        labels_test = np.zeros(N_test, dtype=int)  # Создаем массив из нулей\n",
    "        labels_test[3::5] = 1  # Каждый 4-й элемен\n",
    "        print(classification_report(labels_test, model.predict(matrix_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportional_train_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_HC/auc.npy'\n",
    "proportional_test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_test/auc.npy'\n",
    "\n",
    "reduced_train_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/auc_raw_HC.npy'\n",
    "reduced_test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/auc_test.npy'\n",
    "\n",
    "ranks_train_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_HC/auc.npy'\n",
    "ranks_test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_test/auc.npy'\n",
    "\n",
    "# train_matrix  = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/HC/max.npy'\n",
    "# test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/test/max.npy'\n",
    "\n",
    "train_matrix = proportional_train_matrix\n",
    "test_matrix = proportional_test_matrix \n",
    "\n",
    "# train_matrix = ranks_train_matrix\n",
    "# test_matrix = ranks_test_matrix\n",
    "\n",
    "# train_matrix = reduced_train_matrix\n",
    "# test_matrix = reduced_test_matrix\n",
    "\n",
    "train_matrix, test_matrix = test_matrix, train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_different_params(train_matrix_base, test_matrix_base):\n",
    "    for func_name in funcs.keys():\n",
    "        if func_name in ('max_min', 'min'):\n",
    "            continue\n",
    "        train_matrix = os.path.join(train_matrix_base, func_name + '.npy')\n",
    "        test_matrix = os.path.join(test_matrix_base, func_name + '.npy')\n",
    "\n",
    "        print('-'*10 + func_name + '-'*10)\n",
    "        train_and_predict_on_test(train_matrix, test_matrix)\n",
    "        print('-' * 100, sep='\\n\\n\\n\\n\\n\\n')\n",
    "\n",
    "        train_matrix, test_matrix = test_matrix, train_matrix\n",
    "\n",
    "        print('TEST AND TRAIN DATA REVERT' * 10)\n",
    "        print('-'*10 + func_name + '-'*10)\n",
    "        train_and_predict_on_test(train_matrix, test_matrix)\n",
    "        print('-' * 100, sep='\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пропорциональные баллы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.765 ± 0.424\n",
      "Random Forest        | Recall (class 1): 0.235 ± 0.424\n",
      "SVM                  | Recall (class 1): 0.353 ± 0.478\n",
      "XGBoost              | Recall (class 1): 0.647 ± 0.478\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       0.20      1.00      0.33        17\n",
      "\n",
      "    accuracy                           0.20        85\n",
      "   macro avg       0.10      0.50      0.17        85\n",
      "weighted avg       0.04      0.20      0.07        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       0.20      1.00      0.33        17\n",
      "\n",
      "    accuracy                           0.20        85\n",
      "   macro avg       0.10      0.50      0.17        85\n",
      "weighted avg       0.04      0.20      0.07        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------auc----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  | Recall (class 1): 0.412 ± 0.492\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.059 ± 0.235\n",
      "XGBoost              | Recall (class 1): 0.294 ± 0.456\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------max----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  | Recall (class 1): 0.529 ± 0.499\n",
      "Random Forest        | Recall (class 1): 0.353 ± 0.478\n",
      "SVM                  | Recall (class 1): 0.529 ± 0.499\n",
      "XGBoost              | Recall (class 1): 0.588 ± 0.492\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       0.20      1.00      0.33        17\n",
      "\n",
      "    accuracy                           0.20        85\n",
      "   macro avg       0.10      0.50      0.17        85\n",
      "weighted avg       0.04      0.20      0.07        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       0.20      1.00      0.33        17\n",
      "\n",
      "    accuracy                           0.20        85\n",
      "   macro avg       0.10      0.50      0.17        85\n",
      "weighted avg       0.04      0.20      0.07        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       0.20      1.00      0.33        17\n",
      "\n",
      "    accuracy                           0.20        85\n",
      "   macro avg       0.10      0.50      0.17        85\n",
      "weighted avg       0.04      0.20      0.07        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------max----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  | Recall (class 1): 0.353 ± 0.478\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.118 ± 0.322\n",
      "XGBoost              | Recall (class 1): 0.118 ± 0.322\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_hc_data'\n",
    "test_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_test_data'\n",
    "\n",
    "schz_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_schz_data'\n",
    "\n",
    "cards_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_card_hc_data'\n",
    "\n",
    "# train_different_params(train_matrix_base, test_matrix_base)\n",
    "\n",
    "train_different_params(train_matrix_base, cards_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Баллы по 1,2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.647 ± 0.478\n",
      "Random Forest        | Recall (class 1): 0.294 ± 0.456\n",
      "SVM                  | Recall (class 1): 0.471 ± 0.499\n",
      "XGBoost              | Recall (class 1): 0.588 ± 0.492\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86        56\n",
      "           1       0.29      0.14      0.19        14\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.55      0.53      0.52        70\n",
      "weighted avg       0.70      0.76      0.72        70\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88        56\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.79        70\n",
      "   macro avg       0.40      0.49      0.44        70\n",
      "weighted avg       0.64      0.79      0.70        70\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.91      0.86        56\n",
      "           1       0.29      0.14      0.19        14\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.55      0.53      0.52        70\n",
      "weighted avg       0.70      0.76      0.72        70\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82        56\n",
      "           1       0.25      0.21      0.23        14\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.53      0.53      0.53        70\n",
      "weighted avg       0.70      0.71      0.71        70\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.500 ± 0.500\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.286 ± 0.452\n",
      "XGBoost              | Recall (class 1): 0.357 ± 0.479\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87        68\n",
      "           1       0.42      0.29      0.34        17\n",
      "\n",
      "    accuracy                           0.78        85\n",
      "   macro avg       0.63      0.60      0.61        85\n",
      "weighted avg       0.75      0.78      0.76        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87        68\n",
      "           1       0.25      0.06      0.10        17\n",
      "\n",
      "    accuracy                           0.78        85\n",
      "   macro avg       0.53      0.51      0.48        85\n",
      "weighted avg       0.69      0.78      0.72        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83        68\n",
      "           1       0.11      0.06      0.08        17\n",
      "\n",
      "    accuracy                           0.72        85\n",
      "   macro avg       0.45      0.47      0.46        85\n",
      "weighted avg       0.65      0.72      0.68        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------max----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  | Recall (class 1): 0.588 ± 0.492\n",
      "Random Forest        | Recall (class 1): 0.471 ± 0.499\n",
      "SVM                  | Recall (class 1): 0.588 ± 0.492\n",
      "XGBoost              | Recall (class 1): 0.529 ± 0.499\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83        56\n",
      "           1       0.12      0.07      0.09        14\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.46      0.47      0.46        70\n",
      "weighted avg       0.66      0.71      0.68        70\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88        56\n",
      "           1       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.79        70\n",
      "   macro avg       0.40      0.49      0.44        70\n",
      "weighted avg       0.64      0.79      0.70        70\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87        56\n",
      "           1       0.25      0.07      0.11        14\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.53      0.51      0.49        70\n",
      "weighted avg       0.69      0.77      0.72        70\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85        56\n",
      "           1       0.33      0.21      0.26        14\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.58      0.55      0.56        70\n",
      "weighted avg       0.72      0.76      0.74        70\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------max----------\n",
      "Logistic Regression  | Recall (class 1): 0.429 ± 0.495\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.000 ± 0.000\n",
      "XGBoost              | Recall (class 1): 0.143 ± 0.350\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85        68\n",
      "           1       0.30      0.18      0.22        17\n",
      "\n",
      "    accuracy                           0.75        85\n",
      "   macro avg       0.56      0.54      0.54        85\n",
      "weighted avg       0.71      0.75      0.73        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.79        85\n",
      "   macro avg       0.40      0.49      0.44        85\n",
      "weighted avg       0.64      0.79      0.71        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85        68\n",
      "           1       0.30      0.18      0.22        17\n",
      "\n",
      "    accuracy                           0.75        85\n",
      "   macro avg       0.56      0.54      0.54        85\n",
      "weighted avg       0.71      0.75      0.73        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "reduced_train_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/raw_hc_data'\n",
    "reduced_test_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/raw_test_data'\n",
    "\n",
    "\n",
    "reduced_schz_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/raw_schz_data'\n",
    "\n",
    "# train_different_params(reduced_train_matrix_base, reduced_test_matrix_base)\n",
    "\n",
    "train_different_params(reduced_train_matrix_base, reduced_schz_matrix_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Просто баллы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.647 ± 0.478\n",
      "Random Forest        | Recall (class 1): 0.235 ± 0.424\n",
      "SVM                  | Recall (class 1): 0.706 ± 0.456\n",
      "XGBoost              | Recall (class 1): 0.471 ± 0.499\n",
      "Model: Logistic Regression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m ranks_schz_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_schz_data\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# train_different_params(ranks_train_matrix, ranks_test_matrix)\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mtrain_different_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mranks_train_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranks_schz_matrix\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 9\u001b[0m, in \u001b[0;36mtrain_different_params\u001b[0;34m(train_matrix_base, test_matrix_base)\u001b[0m\n\u001b[1;32m      6\u001b[0m test_matrix \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_matrix_base, func_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m func_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain_and_predict_on_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m train_matrix, test_matrix \u001b[38;5;241m=\u001b[39m test_matrix, train_matrix\n",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m, in \u001b[0;36mtrain_and_predict_on_test\u001b[0;34m(train_matrix, test_matrix)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     matrix_test \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     N_test \u001b[38;5;241m=\u001b[39m matrix_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Длина массива\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     sub_num_test \u001b[38;5;241m=\u001b[39m N_test \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py:413\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode)\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/format.py:741\u001b[0m, in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mhasobject:\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;66;03m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[1;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n\u001b[0;32m--> 741\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObject arrays cannot be loaded when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    742\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_pickle=False\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pickle_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    744\u001b[0m         pickle_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "ranks_train_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_hc_data'\n",
    "ranks_test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_test_data'\n",
    "\n",
    "ranks_schz_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_schz_data'\n",
    "\n",
    "# train_different_params(ranks_train_matrix, ranks_test_matrix)\n",
    "\n",
    "train_different_params(ranks_train_matrix, ranks_schz_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.588 ± 0.492\n",
      "Random Forest        | Recall (class 1): 0.471 ± 0.499\n",
      "SVM                  | Recall (class 1): 0.588 ± 0.492\n",
      "XGBoost              | Recall (class 1): 0.412 ± 0.492\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86        56\n",
      "           1       0.40      0.29      0.33        14\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.62      0.59      0.60        70\n",
      "weighted avg       0.75      0.77      0.76        70\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88        56\n",
      "           1       0.40      0.14      0.21        14\n",
      "\n",
      "    accuracy                           0.79        70\n",
      "   macro avg       0.61      0.54      0.54        70\n",
      "weighted avg       0.73      0.79      0.74        70\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82        56\n",
      "           1       0.29      0.29      0.29        14\n",
      "\n",
      "    accuracy                           0.71        70\n",
      "   macro avg       0.55      0.55      0.55        70\n",
      "weighted avg       0.71      0.71      0.71        70\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.77      0.80        56\n",
      "           1       0.28      0.36      0.31        14\n",
      "\n",
      "    accuracy                           0.69        70\n",
      "   macro avg       0.55      0.56      0.55        70\n",
      "weighted avg       0.72      0.69      0.70        70\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.500 ± 0.500\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.214 ± 0.410\n",
      "XGBoost              | Recall (class 1): 0.143 ± 0.350\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.90        68\n",
      "           1       0.71      0.29      0.42        17\n",
      "\n",
      "    accuracy                           0.84        85\n",
      "   macro avg       0.78      0.63      0.66        85\n",
      "weighted avg       0.82      0.84      0.81        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        68\n",
      "           1       0.56      0.29      0.38        17\n",
      "\n",
      "    accuracy                           0.81        85\n",
      "   macro avg       0.70      0.62      0.64        85\n",
      "weighted avg       0.78      0.81      0.79        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88        68\n",
      "           1       0.43      0.18      0.25        17\n",
      "\n",
      "    accuracy                           0.79        85\n",
      "   macro avg       0.62      0.56      0.56        85\n",
      "weighted avg       0.74      0.79      0.75        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------max----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  | Recall (class 1): 0.647 ± 0.478\n",
      "Random Forest        | Recall (class 1): 0.529 ± 0.499\n",
      "SVM                  | Recall (class 1): 0.647 ± 0.478\n",
      "XGBoost              | Recall (class 1): 0.588 ± 0.492\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80        56\n",
      "           1       0.32      0.43      0.36        14\n",
      "\n",
      "    accuracy                           0.70        70\n",
      "   macro avg       0.58      0.60      0.58        70\n",
      "weighted avg       0.74      0.70      0.72        70\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88        56\n",
      "           1       0.50      0.21      0.30        14\n",
      "\n",
      "    accuracy                           0.80        70\n",
      "   macro avg       0.66      0.58      0.59        70\n",
      "weighted avg       0.76      0.80      0.77        70\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86        56\n",
      "           1       0.40      0.29      0.33        14\n",
      "\n",
      "    accuracy                           0.77        70\n",
      "   macro avg       0.62      0.59      0.60        70\n",
      "weighted avg       0.75      0.77      0.76        70\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84        56\n",
      "           1       0.41      0.50      0.45        14\n",
      "\n",
      "    accuracy                           0.76        70\n",
      "   macro avg       0.64      0.66      0.65        70\n",
      "weighted avg       0.78      0.76      0.77        70\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------max----------\n",
      "Logistic Regression  | Recall (class 1): 0.286 ± 0.452\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.000 ± 0.000\n",
      "XGBoost              | Recall (class 1): 0.143 ± 0.350\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.73        85\n",
      "   macro avg       0.39      0.46      0.42        85\n",
      "weighted avg       0.63      0.73      0.67        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.89        68\n",
      "           1       0.67      0.12      0.20        17\n",
      "\n",
      "    accuracy                           0.81        85\n",
      "   macro avg       0.74      0.55      0.55        85\n",
      "weighted avg       0.79      0.81      0.75        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.87        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.78        85\n",
      "   macro avg       0.40      0.49      0.44        85\n",
      "weighted avg       0.64      0.78      0.70        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/hc_data'\n",
    "test_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/test_data'\n",
    "\n",
    "schz_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/schz_data'\n",
    "train_different_params(train_matrix_base, schz_matrix_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.533 ± 0.125\n",
      "Random Forest        | Recall (class 1): 0.133 ± 0.125\n",
      "SVM                  | Recall (class 1): 0.300 ± 0.221\n",
      "XGBoost              | Recall (class 1): 0.300 ± 0.194\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90        40\n",
      "           1       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.77      0.68      0.70        50\n",
      "weighted avg       0.82      0.84      0.82        50\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        40\n",
      "           1       1.00      0.10      0.18        10\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.91      0.55      0.54        50\n",
      "weighted avg       0.85      0.82      0.76        50\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.97      0.91        40\n",
      "           1       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.84        50\n",
      "   macro avg       0.80      0.64      0.67        50\n",
      "weighted avg       0.83      0.84      0.81        50\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92        40\n",
      "           1       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.80      0.72      0.75        50\n",
      "weighted avg       0.85      0.86      0.85        50\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.600 ± 0.133\n",
      "Random Forest        | Recall (class 1): 0.267 ± 0.133\n",
      "SVM                  | Recall (class 1): 0.200 ± 0.267\n",
      "XGBoost              | Recall (class 1): 0.467 ± 0.267\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        68\n",
      "           1       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.89        85\n",
      "   macro avg       0.83      0.85      0.84        85\n",
      "weighted avg       0.90      0.89      0.90        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89        68\n",
      "           1       0.57      0.24      0.33        17\n",
      "\n",
      "    accuracy                           0.81        85\n",
      "   macro avg       0.70      0.60      0.61        85\n",
      "weighted avg       0.78      0.81      0.78        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91        68\n",
      "           1       0.75      0.35      0.48        17\n",
      "\n",
      "    accuracy                           0.85        85\n",
      "   macro avg       0.80      0.66      0.70        85\n",
      "weighted avg       0.84      0.85      0.82        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87        68\n",
      "           1       0.50      0.65      0.56        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.70      0.74      0.72        85\n",
      "weighted avg       0.82      0.80      0.81        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------max----------\n",
      "Logistic Regression  | Recall (class 1): 0.667 ± 0.149\n",
      "Random Forest        | Recall (class 1): 0.467 ± 0.067\n",
      "SVM                  | Recall (class 1): 0.500 ± 0.105\n",
      "XGBoost              | Recall (class 1): 0.667 ± 0.149\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89        40\n",
      "           1       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.72      0.66      0.68        50\n",
      "weighted avg       0.80      0.82      0.81        50\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        40\n",
      "           1       1.00      0.10      0.18        10\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.91      0.55      0.54        50\n",
      "weighted avg       0.85      0.82      0.76        50\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        40\n",
      "           1       1.00      0.30      0.46        10\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.93      0.65      0.69        50\n",
      "weighted avg       0.88      0.86      0.83        50\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87        40\n",
      "           1       0.33      0.10      0.15        10\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.57      0.53      0.51        50\n",
      "weighted avg       0.71      0.78      0.73        50\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------max----------\n",
      "Logistic Regression  | Recall (class 1): 0.600 ± 0.249\n",
      "Random Forest        | Recall (class 1): 0.267 ± 0.133\n",
      "SVM                  | Recall (class 1): 0.067 ± 0.133\n",
      "XGBoost              | Recall (class 1): 0.467 ± 0.267\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        68\n",
      "           1       0.71      0.59      0.65        17\n",
      "\n",
      "    accuracy                           0.87        85\n",
      "   macro avg       0.81      0.76      0.78        85\n",
      "weighted avg       0.86      0.87      0.87        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        68\n",
      "           1       1.00      0.29      0.45        17\n",
      "\n",
      "    accuracy                           0.86        85\n",
      "   macro avg       0.93      0.65      0.69        85\n",
      "weighted avg       0.88      0.86      0.83        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        68\n",
      "           1       0.88      0.41      0.56        17\n",
      "\n",
      "    accuracy                           0.87        85\n",
      "   macro avg       0.87      0.70      0.74        85\n",
      "weighted avg       0.87      0.87      0.85        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        68\n",
      "           1       0.65      0.65      0.65        17\n",
      "\n",
      "    accuracy                           0.86        85\n",
      "   macro avg       0.78      0.78      0.78        85\n",
      "weighted avg       0.86      0.86      0.86        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/prizes/HC'\n",
    "test_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/prizes/test'\n",
    "\n",
    "train_different_params(train_matrix_base, test_matrix_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.706 ± 0.456\n",
      "Random Forest        | Recall (class 1): 0.353 ± 0.478\n",
      "SVM                  | Recall (class 1): 0.588 ± 0.492\n",
      "XGBoost              | Recall (class 1): 0.647 ± 0.478\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        68\n",
      "           1       0.20      0.18      0.19        17\n",
      "\n",
      "    accuracy                           0.69        85\n",
      "   macro avg       0.50      0.50      0.50        85\n",
      "weighted avg       0.68      0.69      0.69        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84        68\n",
      "           1       0.25      0.18      0.21        17\n",
      "\n",
      "    accuracy                           0.73        85\n",
      "   macro avg       0.53      0.52      0.52        85\n",
      "weighted avg       0.70      0.73      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83        68\n",
      "           1       0.27      0.24      0.25        17\n",
      "\n",
      "    accuracy                           0.72        85\n",
      "   macro avg       0.54      0.54      0.54        85\n",
      "weighted avg       0.70      0.72      0.71        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.79      0.80        68\n",
      "           1       0.22      0.24      0.23        17\n",
      "\n",
      "    accuracy                           0.68        85\n",
      "   macro avg       0.51      0.51      0.51        85\n",
      "weighted avg       0.69      0.68      0.69        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------max----------\n",
      "Logistic Regression  | Recall (class 1): 0.706 ± 0.456\n",
      "Random Forest        | Recall (class 1): 0.471 ± 0.499\n",
      "SVM                  | Recall (class 1): 0.647 ± 0.478\n",
      "XGBoost              | Recall (class 1): 0.647 ± 0.478\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83        68\n",
      "           1       0.18      0.12      0.14        17\n",
      "\n",
      "    accuracy                           0.72        85\n",
      "   macro avg       0.49      0.49      0.49        85\n",
      "weighted avg       0.67      0.72      0.69        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        68\n",
      "           1       0.10      0.06      0.07        17\n",
      "\n",
      "    accuracy                           0.71        85\n",
      "   macro avg       0.44      0.46      0.45        85\n",
      "weighted avg       0.65      0.71      0.67        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        68\n",
      "           1       0.10      0.06      0.07        17\n",
      "\n",
      "    accuracy                           0.71        85\n",
      "   macro avg       0.44      0.46      0.45        85\n",
      "weighted avg       0.65      0.71      0.67        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.82        68\n",
      "           1       0.09      0.06      0.07        17\n",
      "\n",
      "    accuracy                           0.69        85\n",
      "   macro avg       0.44      0.46      0.44        85\n",
      "weighted avg       0.65      0.69      0.67        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/HC'\n",
    "test_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/card_hc'\n",
    "for func_name in funcs.keys():\n",
    "    if func_name in ('max_min', 'min'):\n",
    "        continue\n",
    "    train_matrix = os.path.join(train_matrix_base, func_name + '.npy')\n",
    "    test_matrix = os.path.join(test_matrix_base, func_name + '.npy')\n",
    "\n",
    "    print('-'*10 + func_name + '-'*10)\n",
    "    train_and_predict_on_test(train_matrix, test_matrix)\n",
    "    print('-' * 100, sep='\\n\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
