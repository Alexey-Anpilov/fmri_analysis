{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import recall_score, classification_report\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "import numpy as np\n",
    "from fmri_processing.utils import draw_heat_map\n",
    "from fmri_processing.functions import funcs\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_matrix  = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/HC/max.npy'\n",
    "# test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/test/max.npy'\n",
    "\n",
    "# train_matrix, test_matrix = test_matrix, train_matrix\n",
    "def draw_all_subjects(matrix):\n",
    "    N = matrix.shape[0]  # Длина массива\n",
    "    sub_num = N // 5\n",
    "\n",
    "    subjects = np.array_split(matrix, sub_num)\n",
    "    for idx, sub in enumerate(subjects):\n",
    "        print(f'sub-{idx:02d}')\n",
    "        draw_heat_map(subjects[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def z_score_matrix(matrix):\n",
    "    shape = matrix.shape\n",
    "\n",
    "    # 1. Разбиваем матрицу на группы по 5 элементов\n",
    "    flattened = matrix.flatten()  # Преобразуем в 1D-массив\n",
    "    num_groups = len(flattened) // 5\n",
    "    groups = flattened[:num_groups * 5].reshape(-1, 5)  # Группы по 5 элементов\n",
    "\n",
    "    # 2. Вычисляем z-показатели для каждой группы\n",
    "    z_scores = np.zeros_like(groups)\n",
    "    for i in range(groups.shape[0]):\n",
    "        group = groups[i]\n",
    "        mean = np.mean(group)\n",
    "        std = np.std(group)\n",
    "        if std != 0:\n",
    "            z_scores[i] = (group - mean) / std\n",
    "        else:\n",
    "            z_scores[i] = 0  # Если все элементы одинаковые\n",
    "\n",
    "    # 3. Собираем обратно в матрицу\n",
    "    flattened_z = z_scores.flatten()\n",
    "    # Если исходная длина не делилась на 5, добавляем оставшиеся элементы без изменений\n",
    "    if len(flattened) % 5 != 0:\n",
    "        remaining = flattened[num_groups * 5:]\n",
    "        flattened_z = np.concatenate([flattened_z, remaining])\n",
    "\n",
    "    # Преобразуем обратно в исходную размерность\n",
    "    result_matrix = flattened_z.reshape(shape)\n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_matrix):\n",
    "    matrix = np.load(train_matrix)\n",
    "    N = matrix.shape[0]  # Длина массива\n",
    "    sub_num = N // 5    # Количество испытуемых\n",
    "\n",
    "    labels = np.zeros(N, dtype=int)  # Создаем массив из нулей\n",
    "    labels[3::5] = 1  # Каждый 4-й элемен\n",
    "    print(matrix.shape)\n",
    "\n",
    "    X = matrix\n",
    "    y = labels\n",
    "\n",
    "\n",
    "    # Группы для разделения\n",
    "    groups = np.repeat(np.arange(sub_num), 5)  # [0,0,0,0,0, 1,1,1,1,1,...]\n",
    "\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=30)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups))\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model_by_recall_(train_matrix, target_class=1, test_size=0.3, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Обучает модели и возвращает лучшую по recall для указанного класса\n",
    "    \n",
    "    Параметры:\n",
    "    X - признаки\n",
    "    y - целевая переменная\n",
    "    groups - группы для кросс-валидации\n",
    "    target_class - класс, для которого оптимизируем recall (по умолчанию 1)\n",
    "    test_size - доля тестовой выборки\n",
    "    random_state - для воспроизводимости\n",
    "    verbose - вывод информации о процессе обучения\n",
    "    \"\"\"\n",
    "    \n",
    "    matrix = np.load(train_matrix)\n",
    "    N = matrix.shape[0]  # Длина массива\n",
    "    sub_num = N // 5    # Количество испытуемых\n",
    "\n",
    "    labels = np.zeros(N, dtype=int)  # Создаем массив из нулей\n",
    "    labels[3::5] = 1  # Каждый 4-й элемен\n",
    "    print(matrix.shape)\n",
    "\n",
    "    X = matrix\n",
    "    y = labels\n",
    "\n",
    "\n",
    "    # Группы для разделения\n",
    "    groups = np.repeat(np.arange(sub_num), 5)  # [0,0,0,0,0, 1,1,1,1,1,...]\n",
    "\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=30)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups))\n",
    "\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    \n",
    "    \n",
    "    # 1. Разделение на train/test с сохранением групп\n",
    "    splitter = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=random_state)\n",
    "    train_idx, test_idx = next(splitter.split(X, y, groups))\n",
    "    \n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    groups_train = groups[train_idx]\n",
    "    \n",
    "    # 2. Инициализация моделей\n",
    "    models = {\n",
    "        \"Logistic Regression\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LogisticRegression(class_weight='balanced', \n",
    "                                       max_iter=1000, \n",
    "                                       random_state=random_state))\n",
    "        ]),\n",
    "        \"Random Forest\": RandomForestClassifier(class_weight='balanced_subsample', \n",
    "                                              random_state=random_state),\n",
    "        \"SVM\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', SVC(kernel='rbf', \n",
    "                         class_weight='balanced', \n",
    "                         probability=True, \n",
    "                         random_state=random_state))\n",
    "        ]),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            scale_pos_weight=4,  # Автоматический расчет\n",
    "            random_state=random_state\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # 3. Кросс-валидация по группам\n",
    "    gss = GroupShuffleSplit(n_splits=5, test_size=0.3, random_state=random_state)\n",
    "    model_recalls = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        recall_scores = []\n",
    "        \n",
    "        for fold, (train_idx_fold, val_idx_fold) in enumerate(gss.split(X_train, y_train, groups_train)):\n",
    "            model.fit(X_train[train_idx_fold], y_train[train_idx_fold])\n",
    "            y_pred = model.predict(X_train[val_idx_fold])\n",
    "            recall = recall_score(y_train[val_idx_fold], y_pred, pos_label=target_class)\n",
    "            recall_scores.append(recall)\n",
    "        \n",
    "        print(recall_scores)\n",
    "        mean_recall = np.mean(recall_scores)\n",
    "        std_recall = np.std(recall_scores)\n",
    "        model_recalls.append((name, mean_recall, std_recall, model))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{name:<20} | Recall (class {target_class}): {mean_recall:.3f} ± {std_recall:.3f}\")\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "    # # 4. Выбор лучшей модели\n",
    "    # best_name, best_recall, best_std, best_model = max(model_recalls, key=lambda x: x[1])\n",
    "    \n",
    "    # # 5. Финальное обучение на полном train наборе\n",
    "    # best_model.fit(X_train, y_train)\n",
    "    \n",
    "    # # 6. Оценка на тестовом наборе\n",
    "    # test_recall = recall_score(y_test, best_model.predict(X_test), pos_label=target_class)\n",
    "    \n",
    "    # if verbose:\n",
    "    #     print(f\"\\n{'='*50}\")\n",
    "    #     print(f\"BEST MODEL: {best_name}\")\n",
    "    #     print(f\"CV Recall (class {target_class}): {best_recall:.3f} ± {best_std:.3f}\")\n",
    "    #     print(f\"Test Recall (class {target_class}): {test_recall:.3f}\")\n",
    "    #     print(\"=\"*50)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_model_by_recall(train_matrix, target_class=1, test_size=0.3, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Обучает модели и возвращает лучшую по recall для указанного класса\n",
    "    \n",
    "    Параметры:\n",
    "    train_matrix - путь к файлу с матрицей признаков\n",
    "    target_class - класс, для которого оптимизируем recall\n",
    "    test_size - доля валидационной выборки в кросс-валидации\n",
    "    random_state - для воспроизводимости\n",
    "    verbose - вывод информации о процессе обучения\n",
    "    \n",
    "    Возвращает:\n",
    "    Лучшую модель (по recall на валидации), метрики моделей\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Загрузка данных и подготовка\n",
    "    matrix = np.load(train_matrix)\n",
    "    N = matrix.shape[0]\n",
    "    sub_num = N // 5\n",
    "\n",
    "    labels = np.zeros(N, dtype=int)\n",
    "    labels[3::5] = 1\n",
    "    \n",
    "    X = matrix\n",
    "    y = labels\n",
    "    groups = np.repeat(np.arange(sub_num), 5)\n",
    "\n",
    "    # 2. Инициализация моделей\n",
    "    models = {\n",
    "        \"Logistic Regression\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LogisticRegression(class_weight='balanced', \n",
    "                                       max_iter=1000, \n",
    "                                       random_state=random_state))\n",
    "        ]),\n",
    "\n",
    "\n",
    "\n",
    "    }\n",
    "    # from sklearn.model_selection import RandomizedSearchCV\n",
    "    # from scipy.stats import loguniform  # для логарифмического распределения C\n",
    "\n",
    "    # param_dist = {\n",
    "    #     'model__C': loguniform(1e-4, 100),  # C в диапазоне [0.0001, 100]\n",
    "    #     'model__penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    #     'model__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    #     'model__l1_ratio': [0, 0.25, 0.5, 0.75, 1]  # для elasticnet\n",
    "    # }\n",
    "\n",
    "    # random_search = RandomizedSearchCV(\n",
    "    #     estimator=models['Logistic Regression'],\n",
    "    #     param_distributions=param_dist,\n",
    "    #     n_iter=50,  # количество случайных комбинаций\n",
    "    #     scoring='accuracy',\n",
    "    #     cv=5,\n",
    "    #     n_jobs=-1,\n",
    "    #     verbose=1,\n",
    "    #     random_state=random_state\n",
    "    # )\n",
    "\n",
    "    # models['Logistic Regression'] = random_search\n",
    "\n",
    "    # 3. Кросс-валидация по группам\n",
    "    gss = GroupShuffleSplit(n_splits=5, test_size=test_size, random_state=random_state)\n",
    "    model_recalls = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        recall_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in gss.split(X, y, groups):\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    "            y_pred = model.predict(X[val_idx])\n",
    "            recall = recall_score(y[val_idx], y_pred, pos_label=target_class)\n",
    "            recall_scores.append(recall)\n",
    "        \n",
    "        mean_recall = np.mean(recall_scores)\n",
    "        std_recall = np.std(recall_scores)\n",
    "        model_recalls.append((name, mean_recall, std_recall, model))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{name:<20} | Recall (class {target_class}): {mean_recall:.3f} ± {std_recall:.3f}\")\n",
    "        model.fit(X, y)\n",
    "    # # 4. Выбор лучшей модели\n",
    "    # best_model_info = max(model_recalls, key=lambda x: x[1])\n",
    "    # best_model = best_model_info[3]\n",
    "    \n",
    "    # # 5. Финальное обучение на всех данных\n",
    "    # best_model.fit(X, y)\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def train_best_model_by_recall(train_matrix, target_class=1, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Обучает модели и возвращает лучшую по recall для указанного класса\n",
    "    \n",
    "    Параметры:\n",
    "    train_matrix - путь к файлу с матрицей признаков\n",
    "    target_class - класс, для которого оптимизируем recall\n",
    "    random_state - для воспроизводимости\n",
    "    verbose - вывод информации о процессе обучения\n",
    "    \n",
    "    Возвращает:\n",
    "    Лучшую модель (по recall на валидации), метрики моделей\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Загрузка данных и подготовка\n",
    "    matrix = np.load(train_matrix)\n",
    "    N = matrix.shape[0]\n",
    "    sub_num = N // 5\n",
    "\n",
    "    labels = np.zeros(N, dtype=int)\n",
    "    labels[3::5] = 1\n",
    "    \n",
    "    X = matrix\n",
    "    y = labels\n",
    "    groups = np.repeat(np.arange(sub_num), 5)\n",
    "\n",
    "    # 2. Инициализация моделей\n",
    "    models = {\n",
    "        \"Logistic Regression\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LogisticRegression(class_weight='balanced', \n",
    "                                       max_iter=1000, \n",
    "                                       random_state=random_state))\n",
    "        ]),\n",
    "        \"Random Forest\": RandomForestClassifier(\n",
    "            class_weight='balanced_subsample', \n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"SVM\": Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', SVC(kernel='rbf', \n",
    "                         class_weight='balanced', \n",
    "                         probability=True, \n",
    "                         random_state=random_state))\n",
    "        ]),\n",
    "        \"XGBoost\": XGBClassifier(\n",
    "            scale_pos_weight=(len(y) - sum(y)) / sum(y),\n",
    "            random_state=random_state,\n",
    "            eval_metric='logloss'\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # 3. Кросс-валидация с LeaveOneGroupOut\n",
    "    logo = LeaveOneGroupOut()\n",
    "    model_recalls = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        recall_scores = []\n",
    "        \n",
    "        for train_idx, val_idx in logo.split(X, y, groups=groups):\n",
    "            model.fit(X[train_idx], y[train_idx])\n",
    "            y_pred = model.predict(X[val_idx])\n",
    "            recall = recall_score(y[val_idx], y_pred, pos_label=target_class)\n",
    "            recall_scores.append(recall)\n",
    "        \n",
    "        mean_recall = np.mean(recall_scores)\n",
    "        std_recall = np.std(recall_scores)\n",
    "        model_recalls.append((name, mean_recall, std_recall, model))\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{name:<20} | Recall (class {target_class}): {mean_recall:.3f} ± {std_recall:.3f}\")\n",
    "\n",
    "        model.fit(X,y)\n",
    "    # # 4. Выбор и финальное обучение лучшей модели\n",
    "    # best_model_info = max(model_recalls, key=lambda x: x[1])\n",
    "    # best_model = best_model_info[3].fit(X, y)  # Обучаем на всех данных\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut, GroupKFold, GridSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "\n",
    "def train_best_model_by_recall(train_matrix, target_class=1, random_state=42, verbose=True):\n",
    "    \"\"\"\n",
    "    Обучает модели с оптимизацией параметров и возвращает ансамбль моделей\n",
    "    \n",
    "    Изменения:\n",
    "    - Добавлена оптимизация гиперпараметров\n",
    "    - Включено ансамблирование\n",
    "    - Добавлена балансировка классов\n",
    "    - Улучшена обработка групп\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Загрузка данных и подготовка\n",
    "    matrix = np.load(train_matrix)\n",
    "    N = matrix.shape[0]\n",
    "    sub_num = N // 5\n",
    "\n",
    "    labels = np.zeros(N, dtype=int)\n",
    "    labels[3::5] = 1\n",
    "    \n",
    "    X = matrix\n",
    "    y = labels\n",
    "    groups = np.repeat(np.arange(sub_num), 5)\n",
    "\n",
    "    # 2. Определение пайплайнов с балансировкой\n",
    "    def create_pipeline(model):\n",
    "        return ImbPipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('smote', SMOTE(random_state=random_state)),\n",
    "            ('model', model)\n",
    "        ])\n",
    "\n",
    "    # 3. Инициализация моделей с параметрами для оптимизации\n",
    "    models = {\n",
    "        \"Logistic Regression\": {\n",
    "            'pipeline': create_pipeline(LogisticRegression(max_iter=1000)),\n",
    "            'params': {\n",
    "                'model__C': [0.1, 1, 10],\n",
    "                'model__class_weight': ['balanced', None],\n",
    "                'model__solver': ['lbfgs', 'saga']\n",
    "            }\n",
    "        },\n",
    "        \"Random Forest\": {\n",
    "            'pipeline': create_pipeline(RandomForestClassifier()),\n",
    "            'params': {\n",
    "                'model__n_estimators': [100, 200],\n",
    "                'model__max_depth': [None, 10],\n",
    "                'model__class_weight': ['balanced_subsample', None]\n",
    "            }\n",
    "        },\n",
    "        \"SVM\": {\n",
    "            'pipeline': create_pipeline(SVC(probability=True)),\n",
    "            'params': {\n",
    "                'model__C': [0.1, 1, 10],\n",
    "                'model__kernel': ['rbf', 'linear'],\n",
    "                'model__class_weight': ['balanced', None]\n",
    "            }\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            'pipeline': create_pipeline(XGBClassifier(eval_metric='logloss')),\n",
    "            'params': {\n",
    "                'model__scale_pos_weight': [1, (len(y) - sum(y)) / sum(y)],\n",
    "                'model__max_depth': [3, 5],\n",
    "                'model__learning_rate': [0.1, 0.01]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # 4. Оптимизация гиперпараметров с групповой валидацией\n",
    "    optimized_models = {}\n",
    "    recall_scorer = make_scorer(recall_score, pos_label=target_class)\n",
    "    \n",
    "    for name, config in models.items():\n",
    "        gs = GridSearchCV(\n",
    "            estimator=config['pipeline'],\n",
    "            param_grid=config['params'],\n",
    "            cv=GroupKFold(n_splits=5),\n",
    "            scoring=recall_scorer,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        gs.fit(X, y, groups=groups)\n",
    "        optimized_models[name] = gs.best_estimator_\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"{name} - лучшие параметры: {gs.best_params_}\")\n",
    "            print(f\"Recall (CV): {gs.best_score_:.3f}\\n\")\n",
    "\n",
    "    # 5. Создание ансамбля\n",
    "    ensemble = VotingClassifier(\n",
    "        estimators=[(name, model) for name, model in optimized_models.items()],\n",
    "        voting='soft',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # 6. Обучение ансамбля с групповой валидацией\n",
    "    logo = LeaveOneGroupOut()\n",
    "    recall_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in logo.split(X, y, groups=groups):\n",
    "        ensemble.fit(X[train_idx], y[train_idx])\n",
    "        y_pred = ensemble.predict(X[val_idx])\n",
    "        recall = recall_score(y[val_idx], y_pred, pos_label=target_class)\n",
    "        recall_scores.append(recall)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Ансамбль - Recall: {np.mean(recall_scores):.3f} ± {np.std(recall_scores):.3f}\")\n",
    "    \n",
    "    # 7. Финальное обучение на всех данных\n",
    "    final_models = {**optimized_models, 'Ensemble': ensemble.fit(X, y)}\n",
    "    \n",
    "    return final_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_on_test(train_matrix, test_matrix):\n",
    "    models = train_best_model_by_recall(train_matrix)\n",
    "    for name, model in models.items():\n",
    "        print(f'Model: {name}')\n",
    "        matrix_test = np.load(test_matrix)\n",
    "        N_test = matrix_test.shape[0]  # Длина массива\n",
    "        sub_num_test = N_test // 5\n",
    "\n",
    "        labels_test = np.zeros(N_test, dtype=int)  # Создаем массив из нулей\n",
    "        labels_test[3::5] = 1  # Каждый 4-й элемен\n",
    "        print(model.predict(matrix_test))\n",
    "        print(classification_report(labels_test, model.predict(matrix_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportional_train_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_HC/auc.npy'\n",
    "proportional_test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_test/auc.npy'\n",
    "\n",
    "reduced_train_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/auc_raw_HC.npy'\n",
    "reduced_test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/auc_test.npy'\n",
    "\n",
    "ranks_train_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_HC/auc.npy'\n",
    "ranks_test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_test/auc.npy'\n",
    "\n",
    "# train_matrix  = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/HC/max.npy'\n",
    "# test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/test/max.npy'\n",
    "\n",
    "train_matrix = proportional_train_matrix\n",
    "test_matrix = proportional_test_matrix \n",
    "\n",
    "# train_matrix = ranks_train_matrix\n",
    "# test_matrix = ranks_test_matrix\n",
    "\n",
    "# train_matrix = reduced_train_matrix\n",
    "# test_matrix = reduced_test_matrix\n",
    "\n",
    "train_matrix, test_matrix = test_matrix, train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_different_params(train_matrix_base, test_matrix_base):\n",
    "    for func_name in funcs.keys():\n",
    "        if func_name in ('max_min', 'min'):\n",
    "            continue\n",
    "        train_matrix = os.path.join(train_matrix_base, func_name + '.npy')\n",
    "        test_matrix = os.path.join(test_matrix_base, func_name + '.npy')\n",
    "\n",
    "        print('-'*10 + func_name + '-'*10)\n",
    "        train_and_predict_on_test(train_matrix, test_matrix)\n",
    "        print('-' * 100, sep='\\n\\n\\n\\n\\n\\n')\n",
    "\n",
    "        train_matrix, test_matrix = test_matrix, train_matrix\n",
    "\n",
    "        print('TEST AND TRAIN DATA REVERT' * 10)\n",
    "        print('-'*10 + func_name + '-'*10)\n",
    "        train_and_predict_on_test(train_matrix, test_matrix)\n",
    "        print('-' * 100, sep='\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пропорциональные баллы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = np.load(cards_matrix+'/auc.npy')\n",
    "\n",
    "draw_all_subjects(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.600 ± 0.490\n",
      "Random Forest        | Recall (class 1): 0.200 ± 0.400\n",
      "SVM                  | Recall (class 1): 0.100 ± 0.300\n",
      "XGBoost              | Recall (class 1): 0.300 ± 0.458\n",
      "Model: Logistic Regression\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       0.20      1.00      0.33        17\n",
      "\n",
      "    accuracy                           0.20        85\n",
      "   macro avg       0.10      0.50      0.17        85\n",
      "weighted avg       0.04      0.20      0.07        85\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: XGBoost\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       0.20      1.00      0.33        17\n",
      "\n",
      "    accuracy                           0.20        85\n",
      "   macro avg       0.10      0.50      0.17        85\n",
      "weighted avg       0.04      0.20      0.07        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.412 ± 0.492\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.059 ± 0.235\n",
      "XGBoost              | Recall (class 1): 0.294 ± 0.456\n",
      "Model: Logistic Regression\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        40\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.40      0.50      0.44        50\n",
      "weighted avg       0.64      0.80      0.71        50\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        40\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.40      0.50      0.44        50\n",
      "weighted avg       0.64      0.80      0.71        50\n",
      "\n",
      "Model: SVM\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        40\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.40      0.50      0.44        50\n",
      "weighted avg       0.64      0.80      0.71        50\n",
      "\n",
      "Model: XGBoost\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        40\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.40      0.50      0.44        50\n",
      "weighted avg       0.64      0.80      0.71        50\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------max----------\n",
      "Logistic Regression  | Recall (class 1): 0.500 ± 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest        | Recall (class 1): 0.300 ± 0.458\n",
      "SVM                  | Recall (class 1): 0.100 ± 0.300\n",
      "XGBoost              | Recall (class 1): 0.400 ± 0.490\n",
      "Model: Logistic Regression\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       0.20      1.00      0.33        17\n",
      "\n",
      "    accuracy                           0.20        85\n",
      "   macro avg       0.10      0.50      0.17        85\n",
      "weighted avg       0.04      0.20      0.07        85\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: XGBoost\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       0.20      1.00      0.33        17\n",
      "\n",
      "    accuracy                           0.20        85\n",
      "   macro avg       0.10      0.50      0.17        85\n",
      "weighted avg       0.04      0.20      0.07        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------max----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  | Recall (class 1): 0.353 ± 0.478\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.118 ± 0.322\n",
      "XGBoost              | Recall (class 1): 0.118 ± 0.322\n",
      "Model: Logistic Regression\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        40\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.40      0.50      0.44        50\n",
      "weighted avg       0.64      0.80      0.71        50\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        40\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.40      0.50      0.44        50\n",
      "weighted avg       0.64      0.80      0.71        50\n",
      "\n",
      "Model: SVM\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        40\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.40      0.50      0.44        50\n",
      "weighted avg       0.64      0.80      0.71        50\n",
      "\n",
      "Model: XGBoost\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        40\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.40      0.50      0.44        50\n",
      "weighted avg       0.64      0.80      0.71        50\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_hc_data'\n",
    "test_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_test_data'\n",
    "\n",
    "schz_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_schz_data'\n",
    "\n",
    "cards_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/proportional/raw_card_hc_data'\n",
    "\n",
    "# train_different_params(train_matrix_base, test_matrix_base)\n",
    "\n",
    "train_different_params(test_matrix_base, cards_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Баллы по 1,2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = np.load(reduced_cards_matrix_base+'/auc.npy')\n",
    "\n",
    "draw_all_subjects(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.647 ± 0.478\n",
      "Random Forest        | Recall (class 1): 0.294 ± 0.456\n",
      "SVM                  | Recall (class 1): 0.471 ± 0.499\n",
      "XGBoost              | Recall (class 1): 0.588 ± 0.492\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81        68\n",
      "           1       0.26      0.29      0.28        17\n",
      "\n",
      "    accuracy                           0.69        85\n",
      "   macro avg       0.54      0.54      0.54        85\n",
      "weighted avg       0.71      0.69      0.70        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        68\n",
      "           1       0.23      0.18      0.20        17\n",
      "\n",
      "    accuracy                           0.72        85\n",
      "   macro avg       0.52      0.51      0.51        85\n",
      "weighted avg       0.69      0.72      0.70        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        68\n",
      "           1       0.24      0.24      0.24        17\n",
      "\n",
      "    accuracy                           0.69        85\n",
      "   macro avg       0.52      0.52      0.52        85\n",
      "weighted avg       0.69      0.69      0.69        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78        68\n",
      "           1       0.26      0.35      0.30        17\n",
      "\n",
      "    accuracy                           0.67        85\n",
      "   macro avg       0.54      0.55      0.54        85\n",
      "weighted avg       0.71      0.67      0.69        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.118 ± 0.322\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.059 ± 0.235\n",
      "XGBoost              | Recall (class 1): 0.000 ± 0.000\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79        68\n",
      "           1       0.07      0.06      0.06        17\n",
      "\n",
      "    accuracy                           0.66        85\n",
      "   macro avg       0.42      0.43      0.43        85\n",
      "weighted avg       0.63      0.66      0.65        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83        68\n",
      "           1       0.11      0.06      0.08        17\n",
      "\n",
      "    accuracy                           0.72        85\n",
      "   macro avg       0.45      0.47      0.46        85\n",
      "weighted avg       0.65      0.72      0.68        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        68\n",
      "           1       0.10      0.06      0.07        17\n",
      "\n",
      "    accuracy                           0.71        85\n",
      "   macro avg       0.44      0.46      0.45        85\n",
      "weighted avg       0.65      0.71      0.67        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------max----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  | Recall (class 1): 0.588 ± 0.492\n",
      "Random Forest        | Recall (class 1): 0.471 ± 0.499\n",
      "SVM                  | Recall (class 1): 0.588 ± 0.492\n",
      "XGBoost              | Recall (class 1): 0.529 ± 0.499\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.75      0.78        68\n",
      "           1       0.26      0.35      0.30        17\n",
      "\n",
      "    accuracy                           0.67        85\n",
      "   macro avg       0.54      0.55      0.54        85\n",
      "weighted avg       0.71      0.67      0.69        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85        68\n",
      "           1       0.22      0.12      0.15        17\n",
      "\n",
      "    accuracy                           0.74        85\n",
      "   macro avg       0.51      0.51      0.50        85\n",
      "weighted avg       0.69      0.74      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79        68\n",
      "           1       0.21      0.24      0.22        17\n",
      "\n",
      "    accuracy                           0.67        85\n",
      "   macro avg       0.51      0.51      0.51        85\n",
      "weighted avg       0.68      0.67      0.68        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79        68\n",
      "           1       0.31      0.47      0.37        17\n",
      "\n",
      "    accuracy                           0.68        85\n",
      "   macro avg       0.58      0.60      0.58        85\n",
      "weighted avg       0.74      0.68      0.70        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------max----------\n",
      "Logistic Regression  | Recall (class 1): 0.118 ± 0.322\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.000 ± 0.000\n",
      "XGBoost              | Recall (class 1): 0.118 ± 0.322\n",
      "Model: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87        68\n",
      "           1       0.47      0.53      0.50        17\n",
      "\n",
      "    accuracy                           0.79        85\n",
      "   macro avg       0.68      0.69      0.68        85\n",
      "weighted avg       0.80      0.79      0.79        85\n",
      "\n",
      "Model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87        68\n",
      "           1       0.33      0.12      0.17        17\n",
      "\n",
      "    accuracy                           0.78        85\n",
      "   macro avg       0.57      0.53      0.52        85\n",
      "weighted avg       0.71      0.78      0.73        85\n",
      "\n",
      "Model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87        68\n",
      "           1       0.47      0.47      0.47        17\n",
      "\n",
      "    accuracy                           0.79        85\n",
      "   macro avg       0.67      0.67      0.67        85\n",
      "weighted avg       0.79      0.79      0.79        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "reduced_train_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/raw_hc_data'\n",
    "reduced_test_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/raw_test_data'\n",
    "\n",
    "\n",
    "reduced_schz_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/raw_schz_data'\n",
    "\n",
    "reduced_cards_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/reduced_ranks/raw_card_hc_data'\n",
    "\n",
    "\n",
    "# train_different_params(reduced_train_matrix_base, reduced_test_matrix_base)\n",
    "\n",
    "# train_different_params(reduced_train_matrix_base, reduced_schz_matrix_base)\n",
    "\n",
    "train_different_params(reduced_train_matrix_base, reduced_cards_matrix_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Просто баллы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = np.load(ranks_card_hc_matrix+'/auc.npy')\n",
    "\n",
    "draw_all_subjects(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - лучшие параметры: {'model__C': 10, 'model__class_weight': 'balanced', 'model__solver': 'saga'}\n",
      "Recall (CV): 0.700\n",
      "\n",
      "Random Forest - лучшие параметры: {'model__class_weight': 'balanced_subsample', 'model__max_depth': None, 'model__n_estimators': 100}\n",
      "Recall (CV): 0.700\n",
      "\n",
      "SVM - лучшие параметры: {'model__C': 0.1, 'model__class_weight': 'balanced', 'model__kernel': 'linear'}\n",
      "Recall (CV): 0.500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - лучшие параметры: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__scale_pos_weight': 1}\n",
      "Recall (CV): 0.600\n",
      "\n",
      "Ансамбль - Recall: 0.500 ± 0.500\n",
      "Model: Logistic Regression\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 0 1 0\n",
      " 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.92        68\n",
      "           1       0.64      0.82      0.72        17\n",
      "\n",
      "    accuracy                           0.87        85\n",
      "   macro avg       0.79      0.85      0.82        85\n",
      "weighted avg       0.89      0.87      0.88        85\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        68\n",
      "           1       0.69      0.53      0.60        17\n",
      "\n",
      "    accuracy                           0.86        85\n",
      "   macro avg       0.79      0.74      0.76        85\n",
      "weighted avg       0.85      0.86      0.85        85\n",
      "\n",
      "Model: SVM\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 0 0 1 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94        68\n",
      "           1       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.91        85\n",
      "   macro avg       0.85      0.85      0.85        85\n",
      "weighted avg       0.91      0.91      0.91        85\n",
      "\n",
      "Model: XGBoost\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90        68\n",
      "           1       0.58      0.65      0.61        17\n",
      "\n",
      "    accuracy                           0.84        85\n",
      "   macro avg       0.74      0.76      0.75        85\n",
      "weighted avg       0.84      0.84      0.84        85\n",
      "\n",
      "Model: Ensemble\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0\n",
      " 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        68\n",
      "           1       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.89        85\n",
      "   macro avg       0.83      0.85      0.84        85\n",
      "weighted avg       0.90      0.89      0.90        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------auc----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - лучшие параметры: {'model__C': 10, 'model__class_weight': 'balanced', 'model__solver': 'saga'}\n",
      "Recall (CV): 0.667\n",
      "\n",
      "Random Forest - лучшие параметры: {'model__class_weight': None, 'model__max_depth': 10, 'model__n_estimators': 200}\n",
      "Recall (CV): 0.700\n",
      "\n",
      "SVM - лучшие параметры: {'model__C': 0.1, 'model__class_weight': 'balanced', 'model__kernel': 'rbf'}\n",
      "Recall (CV): 0.617\n",
      "\n",
      "XGBoost - лучшие параметры: {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__scale_pos_weight': 4.0}\n",
      "Recall (CV): 0.733\n",
      "\n",
      "Ансамбль - Recall: 0.588 ± 0.492\n",
      "Model: Logistic Regression\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        40\n",
      "           1       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.88      0.79      0.82        50\n",
      "weighted avg       0.90      0.90      0.89        50\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93        40\n",
      "           1       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.86      0.74      0.78        50\n",
      "weighted avg       0.88      0.88      0.87        50\n",
      "\n",
      "Model: SVM\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 0 0 0 0 1 0 1 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.92        40\n",
      "           1       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.80      0.72      0.75        50\n",
      "weighted avg       0.85      0.86      0.85        50\n",
      "\n",
      "Model: XGBoost\n",
      "[0 0 0 1 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0\n",
      " 0 1 0 0 1 0 1 1 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.70      0.79        40\n",
      "           1       0.37      0.70      0.48        10\n",
      "\n",
      "    accuracy                           0.70        50\n",
      "   macro avg       0.64      0.70      0.64        50\n",
      "weighted avg       0.80      0.70      0.73        50\n",
      "\n",
      "Model: Ensemble\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 1 0 0 0 0 1 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        40\n",
      "           1       0.80      0.80      0.80        10\n",
      "\n",
      "    accuracy                           0.92        50\n",
      "   macro avg       0.88      0.88      0.88        50\n",
      "weighted avg       0.92      0.92      0.92        50\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------max----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - лучшие параметры: {'model__C': 10, 'model__class_weight': 'balanced', 'model__solver': 'saga'}\n",
      "Recall (CV): 0.700\n",
      "\n",
      "Random Forest - лучшие параметры: {'model__class_weight': None, 'model__max_depth': 10, 'model__n_estimators': 100}\n",
      "Recall (CV): 0.500\n",
      "\n",
      "SVM - лучшие параметры: {'model__C': 0.1, 'model__class_weight': 'balanced', 'model__kernel': 'linear'}\n",
      "Recall (CV): 0.500\n",
      "\n",
      "XGBoost - лучшие параметры: {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__scale_pos_weight': 4.0}\n",
      "Recall (CV): 0.700\n",
      "\n",
      "Ансамбль - Recall: 0.600 ± 0.490\n",
      "Model: Logistic Regression\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92        68\n",
      "           1       0.67      0.71      0.69        17\n",
      "\n",
      "    accuracy                           0.87        85\n",
      "   macro avg       0.80      0.81      0.80        85\n",
      "weighted avg       0.87      0.87      0.87        85\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        68\n",
      "           1       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.91        85\n",
      "   macro avg       0.86      0.83      0.85        85\n",
      "weighted avg       0.90      0.91      0.90        85\n",
      "\n",
      "Model: SVM\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 1 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93        68\n",
      "           1       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.88        85\n",
      "   macro avg       0.82      0.79      0.81        85\n",
      "weighted avg       0.88      0.88      0.88        85\n",
      "\n",
      "Model: XGBoost\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0\n",
      " 0 0 1 1 0 0 1 0 1 1 0 1 0 0 0 0 1 0 1 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        68\n",
      "           1       0.50      0.71      0.59        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.71      0.76      0.73        85\n",
      "weighted avg       0.83      0.80      0.81        85\n",
      "\n",
      "Model: Ensemble\n",
      "[0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 1 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        68\n",
      "           1       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.91        85\n",
      "   macro avg       0.86      0.83      0.85        85\n",
      "weighted avg       0.90      0.91      0.90        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------max----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - лучшие параметры: {'model__C': 0.1, 'model__class_weight': 'balanced', 'model__solver': 'lbfgs'}\n",
      "Recall (CV): 0.683\n",
      "\n",
      "Random Forest - лучшие параметры: {'model__class_weight': 'balanced_subsample', 'model__max_depth': 10, 'model__n_estimators': 200}\n",
      "Recall (CV): 0.700\n",
      "\n",
      "SVM - лучшие параметры: {'model__C': 10, 'model__class_weight': 'balanced', 'model__kernel': 'rbf'}\n",
      "Recall (CV): 0.633\n",
      "\n",
      "XGBoost - лучшие параметры: {'model__learning_rate': 0.1, 'model__max_depth': 3, 'model__scale_pos_weight': 4.0}\n",
      "Recall (CV): 0.800\n",
      "\n",
      "Ансамбль - Recall: 0.647 ± 0.478\n",
      "Model: Logistic Regression\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        40\n",
      "           1       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.88      0.79      0.82        50\n",
      "weighted avg       0.90      0.90      0.89        50\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        40\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.94      0.75      0.80        50\n",
      "weighted avg       0.91      0.90      0.89        50\n",
      "\n",
      "Model: SVM\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        40\n",
      "           1       1.00      0.30      0.46        10\n",
      "\n",
      "    accuracy                           0.86        50\n",
      "   macro avg       0.93      0.65      0.69        50\n",
      "weighted avg       0.88      0.86      0.83        50\n",
      "\n",
      "Model: XGBoost\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 1 1 0 0 0 0 0 1 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92        40\n",
      "           1       0.67      0.80      0.73        10\n",
      "\n",
      "    accuracy                           0.88        50\n",
      "   macro avg       0.81      0.85      0.83        50\n",
      "weighted avg       0.89      0.88      0.88        50\n",
      "\n",
      "Model: Ensemble\n",
      "[0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        40\n",
      "           1       1.00      0.50      0.67        10\n",
      "\n",
      "    accuracy                           0.90        50\n",
      "   macro avg       0.94      0.75      0.80        50\n",
      "weighted avg       0.91      0.90      0.89        50\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ranks_train_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_hc_data'\n",
    "ranks_test_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_test_data'\n",
    "\n",
    "ranks_schz_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_schz_data'\n",
    "\n",
    "ranks_card_hc_matrix = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/raw_card_hc_data'\n",
    "\n",
    "train_different_params(ranks_test_matrix, ranks_train_matrix)\n",
    "# print('SCHZ'*30)\n",
    "# train_different_params(ranks_test_matrix, ranks_schz_matrix)\n",
    "\n",
    "# train_different_params(ranks_test_matrix, ranks_card_hc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = np.load(test_matrix_base+'/auc.npy')\n",
    "\n",
    "draw_all_subjects(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.588 ± 0.492\n",
      "Random Forest        | Recall (class 1): 0.471 ± 0.499\n",
      "SVM                  | Recall (class 1): 0.588 ± 0.492\n",
      "XGBoost              | Recall (class 1): 0.412 ± 0.492\n",
      "Model: Logistic Regression\n",
      "[0 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85        68\n",
      "           1       0.33      0.24      0.28        17\n",
      "\n",
      "    accuracy                           0.75        85\n",
      "   macro avg       0.58      0.56      0.56        85\n",
      "weighted avg       0.72      0.75      0.74        85\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84        68\n",
      "           1       0.12      0.06      0.08        17\n",
      "\n",
      "    accuracy                           0.73        85\n",
      "   macro avg       0.46      0.48      0.46        85\n",
      "weighted avg       0.66      0.73      0.69        85\n",
      "\n",
      "Model: SVM\n",
      "[0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.82      0.81        68\n",
      "           1       0.20      0.18      0.19        17\n",
      "\n",
      "    accuracy                           0.69        85\n",
      "   macro avg       0.50      0.50      0.50        85\n",
      "weighted avg       0.68      0.69      0.69        85\n",
      "\n",
      "Model: XGBoost\n",
      "[0 1 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.79        68\n",
      "           1       0.24      0.29      0.26        17\n",
      "\n",
      "    accuracy                           0.67        85\n",
      "   macro avg       0.53      0.53      0.53        85\n",
      "weighted avg       0.70      0.67      0.68        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.294 ± 0.456\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.176 ± 0.381\n",
      "XGBoost              | Recall (class 1): 0.294 ± 0.456\n",
      "Model: Logistic Regression\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 1 0 0 0 1 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81        68\n",
      "           1       0.28      0.29      0.29        17\n",
      "\n",
      "    accuracy                           0.71        85\n",
      "   macro avg       0.55      0.55      0.55        85\n",
      "weighted avg       0.71      0.71      0.71        85\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        68\n",
      "           1       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.81        85\n",
      "   macro avg       0.90      0.53      0.50        85\n",
      "weighted avg       0.85      0.81      0.74        85\n",
      "\n",
      "Model: SVM\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 1 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 1 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82        68\n",
      "           1       0.32      0.35      0.33        17\n",
      "\n",
      "    accuracy                           0.72        85\n",
      "   macro avg       0.57      0.58      0.58        85\n",
      "weighted avg       0.73      0.72      0.72        85\n",
      "\n",
      "Model: XGBoost\n",
      "[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1\n",
      " 0 1 0 0 0 0 0 0 0 0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84        68\n",
      "           1       0.25      0.18      0.21        17\n",
      "\n",
      "    accuracy                           0.73        85\n",
      "   macro avg       0.53      0.52      0.52        85\n",
      "weighted avg       0.70      0.73      0.71        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------max----------\n",
      "Logistic Regression  | Recall (class 1): 0.647 ± 0.478\n",
      "Random Forest        | Recall (class 1): 0.529 ± 0.499\n",
      "SVM                  | Recall (class 1): 0.647 ± 0.478\n",
      "XGBoost              | Recall (class 1): 0.588 ± 0.492\n",
      "Model: Logistic Regression\n",
      "[0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83        68\n",
      "           1       0.18      0.12      0.14        17\n",
      "\n",
      "    accuracy                           0.72        85\n",
      "   macro avg       0.49      0.49      0.49        85\n",
      "weighted avg       0.67      0.72      0.69        85\n",
      "\n",
      "Model: Random Forest\n",
      "[0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83        68\n",
      "           1       0.10      0.06      0.07        17\n",
      "\n",
      "    accuracy                           0.71        85\n",
      "   macro avg       0.44      0.46      0.45        85\n",
      "weighted avg       0.65      0.71      0.67        85\n",
      "\n",
      "Model: SVM\n",
      "[0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.82        68\n",
      "           1       0.09      0.06      0.07        17\n",
      "\n",
      "    accuracy                           0.69        85\n",
      "   macro avg       0.44      0.46      0.44        85\n",
      "weighted avg       0.65      0.69      0.67        85\n",
      "\n",
      "Model: XGBoost\n",
      "[0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        68\n",
      "           1       0.18      0.18      0.18        17\n",
      "\n",
      "    accuracy                           0.67        85\n",
      "   macro avg       0.49      0.49      0.49        85\n",
      "weighted avg       0.67      0.67      0.67        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "TEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERTTEST AND TRAIN DATA REVERT\n",
      "----------max----------\n",
      "Logistic Regression  | Recall (class 1): 0.471 ± 0.499\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.059 ± 0.235\n",
      "XGBoost              | Recall (class 1): 0.059 ± 0.235\n",
      "Model: Logistic Regression\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 1 1 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83        68\n",
      "           1       0.27      0.24      0.25        17\n",
      "\n",
      "    accuracy                           0.72        85\n",
      "   macro avg       0.54      0.54      0.54        85\n",
      "weighted avg       0.70      0.72      0.71        85\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        68\n",
      "           1       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.80        85\n",
      "   macro avg       0.40      0.50      0.44        85\n",
      "weighted avg       0.64      0.80      0.71        85\n",
      "\n",
      "Model: SVM\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86        68\n",
      "           1       0.20      0.06      0.09        17\n",
      "\n",
      "    accuracy                           0.76        85\n",
      "   macro avg       0.50      0.50      0.48        85\n",
      "weighted avg       0.68      0.76      0.71        85\n",
      "\n",
      "Model: XGBoost\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.94      0.87        68\n",
      "           1       0.33      0.12      0.17        17\n",
      "\n",
      "    accuracy                           0.78        85\n",
      "   macro avg       0.57      0.53      0.52        85\n",
      "weighted avg       0.71      0.78      0.73        85\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/hc_data'\n",
    "test_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/test_data'\n",
    "\n",
    "schz_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/schz_data'\n",
    "card_train_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/card_hc_data'\n",
    "card_test_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/card_test_data'\n",
    "\n",
    "train_different_params(train_matrix_base, card_train_matrix_base)\n",
    "# print('SCHZ'*20)\n",
    "# train_different_params(test_matrix_base, train_matrix_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/prizes/HC'\n",
    "test_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/ranks_matrix/prizes/test'\n",
    "\n",
    "\n",
    "train_different_params(train_matrix_base, test_matrix_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------auc----------\n",
      "Logistic Regression  | Recall (class 1): 0.294 ± 0.456\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.206 ± 0.404\n",
      "XGBoost              | Recall (class 1): 0.059 ± 0.235\n",
      "Model: Logistic Regression\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 1 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 1 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84        40\n",
      "           1       0.33      0.30      0.32        10\n",
      "\n",
      "    accuracy                           0.74        50\n",
      "   macro avg       0.58      0.57      0.58        50\n",
      "weighted avg       0.73      0.74      0.73        50\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        40\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.40      0.50      0.44        50\n",
      "weighted avg       0.64      0.80      0.71        50\n",
      "\n",
      "Model: SVM\n",
      "[0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 0 1 1 0 0 1\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74        40\n",
      "           1       0.14      0.20      0.17        10\n",
      "\n",
      "    accuracy                           0.60        50\n",
      "   macro avg       0.46      0.45      0.45        50\n",
      "weighted avg       0.65      0.60      0.62        50\n",
      "\n",
      "Model: XGBoost\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87        40\n",
      "           1       0.33      0.10      0.15        10\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.57      0.53      0.51        50\n",
      "weighted avg       0.71      0.78      0.73        50\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------max----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression  | Recall (class 1): 0.235 ± 0.424\n",
      "Random Forest        | Recall (class 1): 0.000 ± 0.000\n",
      "SVM                  | Recall (class 1): 0.029 ± 0.169\n",
      "XGBoost              | Recall (class 1): 0.000 ± 0.000\n",
      "Model: Logistic Regression\n",
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81        40\n",
      "           1       0.27      0.30      0.29        10\n",
      "\n",
      "    accuracy                           0.70        50\n",
      "   macro avg       0.55      0.55      0.55        50\n",
      "weighted avg       0.71      0.70      0.71        50\n",
      "\n",
      "Model: Random Forest\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        40\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.40      0.50      0.44        50\n",
      "weighted avg       0.64      0.80      0.71        50\n",
      "\n",
      "Model: SVM\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87        40\n",
      "           1       0.33      0.10      0.15        10\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.57      0.53      0.51        50\n",
      "weighted avg       0.71      0.78      0.73        50\n",
      "\n",
      "Model: XGBoost\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88        40\n",
      "           1       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.78        50\n",
      "   macro avg       0.40      0.49      0.44        50\n",
      "weighted avg       0.64      0.78      0.70        50\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/aaanpilov/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/card_hc_data'\n",
    "test_matrix_base = '/home/aaanpilov/diploma/project/numpy_matrixes/average_stimulus/card_test_data'\n",
    "for func_name in funcs.keys():\n",
    "    if func_name in ('max_min', 'min'):\n",
    "        continue\n",
    "    train_matrix = os.path.join(train_matrix_base, func_name + '.npy')\n",
    "    test_matrix = os.path.join(test_matrix_base, func_name + '.npy')\n",
    "\n",
    "    print('-'*10 + func_name + '-'*10)\n",
    "    train_and_predict_on_test(train_matrix, test_matrix)\n",
    "    print('-' * 100, sep='\\n\\n\\n\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
